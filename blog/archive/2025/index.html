<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Site Description"><meta name=author content="Marcelo Acosta Cavalero"><link href=http://www.marcelops.com/blog/archive/2025/ rel=canonical><link href=../../category/web-development/ rel=prev><link href=../2024/ rel=next><link rel=icon href=../../../assets/images/favicon.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.6.14"><title>2025 - Marcelo Acosta Cavalero</title><link rel=stylesheet href=../../../assets/stylesheets/main.342714a4.min.css><style>:root{--md-admonition-icon--note:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M1%207.775V2.75C1%201.784%201.784%201%202.75%201h5.025c.464%200%20.91.184%201.238.513l6.25%206.25a1.75%201.75%200%200%201%200%202.474l-5.026%205.026a1.75%201.75%200%200%201-2.474%200l-6.25-6.25A1.75%201.75%200%200%201%201%207.775m1.5%200c0%20.066.026.13.073.177l6.25%206.25a.25.25%200%200%200%20.354%200l5.025-5.025a.25.25%200%200%200%200-.354l-6.25-6.25a.25.25%200%200%200-.177-.073H2.75a.25.25%200%200%200-.25.25ZM6%205a1%201%200%201%201%200%202%201%201%200%200%201%200-2%22/%3E%3C/svg%3E');--md-admonition-icon--abstract:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M2.5%201.75v11.5c0%20.138.112.25.25.25h3.17a.75.75%200%200%201%200%201.5H2.75A1.75%201.75%200%200%201%201%2013.25V1.75C1%20.784%201.784%200%202.75%200h8.5C12.216%200%2013%20.784%2013%201.75v7.736a.75.75%200%200%201-1.5%200V1.75a.25.25%200%200%200-.25-.25h-8.5a.25.25%200%200%200-.25.25m13.274%209.537zl-4.557%204.45a.75.75%200%200%201-1.055-.008l-1.943-1.95a.75.75%200%200%201%201.062-1.058l1.419%201.425%204.026-3.932a.75.75%200%201%201%201.048%201.074M4.75%204h4.5a.75.75%200%200%201%200%201.5h-4.5a.75.75%200%200%201%200-1.5M4%207.75A.75.75%200%200%201%204.75%207h2a.75.75%200%200%201%200%201.5h-2A.75.75%200%200%201%204%207.75%22/%3E%3C/svg%3E');--md-admonition-icon--info:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M0%208a8%208%200%201%201%2016%200A8%208%200%200%201%200%208m8-6.5a6.5%206.5%200%201%200%200%2013%206.5%206.5%200%200%200%200-13M6.5%207.75A.75.75%200%200%201%207.25%207h1a.75.75%200%200%201%20.75.75v2.75h.25a.75.75%200%200%201%200%201.5h-2a.75.75%200%200%201%200-1.5h.25v-2h-.25a.75.75%200%200%201-.75-.75M8%206a1%201%200%201%201%200-2%201%201%200%200%201%200%202%22/%3E%3C/svg%3E');--md-admonition-icon--tip:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M3.499.75a.75.75%200%200%201%201.5%200v.996C5.9%202.903%206.793%203.65%207.662%204.376l.24.202c-.036-.694.055-1.422.426-2.163C9.1.873%2010.794-.045%2012.622.26%2014.408.558%2016%201.94%2016%204.25c0%201.278-.954%202.575-2.44%202.734l.146.508.065.22c.203.701.412%201.455.476%202.226.142%201.707-.4%203.03-1.487%203.898C11.714%2014.671%2010.27%2015%208.75%2015h-6a.75.75%200%200%201%200-1.5h1.376a4.5%204.5%200%200%201-.563-1.191%203.84%203.84%200%200%201-.05-2.063%204.65%204.65%200%200%201-2.025-.293.75.75%200%200%201%20.525-1.406c1.357.507%202.376-.006%202.698-.318l.009-.01a.747.747%200%200%201%201.06%200%20.75.75%200%200%201-.012%201.074c-.912.92-.992%201.835-.768%202.586.221.74.745%201.337%201.196%201.621H8.75c1.343%200%202.398-.296%203.074-.836.635-.507%201.036-1.31.928-2.602-.05-.603-.216-1.224-.422-1.93l-.064-.221c-.12-.407-.246-.84-.353-1.29a2.4%202.4%200%200%201-.507-.441%203.1%203.1%200%200%201-.633-1.248.75.75%200%200%201%201.455-.364c.046.185.144.436.31.627.146.168.353.305.712.305.738%200%201.25-.615%201.25-1.25%200-1.47-.95-2.315-2.123-2.51-1.172-.196-2.227.387-2.706%201.345-.46.92-.27%201.774.019%203.062l.042.19.01.05c.348.443.666.949.94%201.553a.75.75%200%201%201-1.365.62c-.553-1.217-1.32-1.94-2.3-2.768L6.7%205.527c-.814-.68-1.75-1.462-2.692-2.619a3.7%203.7%200%200%200-1.023.88c-.406.495-.663%201.036-.722%201.508.116.122.306.21.591.239.388.038.797-.06%201.032-.19a.75.75%200%200%201%20.728%201.31c-.515.287-1.23.439-1.906.373-.682-.067-1.473-.38-1.879-1.193L.75%205.677V5.5c0-.984.48-1.94%201.077-2.664.46-.559%201.05-1.055%201.673-1.353z%22/%3E%3C/svg%3E');--md-admonition-icon--success:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M13.78%204.22a.75.75%200%200%201%200%201.06l-7.25%207.25a.75.75%200%200%201-1.06%200L2.22%209.28a.75.75%200%200%201%20.018-1.042.75.75%200%200%201%201.042-.018L6%2010.94l6.72-6.72a.75.75%200%200%201%201.06%200%22/%3E%3C/svg%3E');--md-admonition-icon--question:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M0%208a8%208%200%201%201%2016%200A8%208%200%200%201%200%208m8-6.5a6.5%206.5%200%201%200%200%2013%206.5%206.5%200%200%200%200-13M6.92%206.085h.001a.749.749%200%201%201-1.342-.67c.169-.339.436-.701.849-.977C6.845%204.16%207.369%204%208%204a2.76%202.76%200%200%201%201.637.525c.503.377.863.965.863%201.725%200%20.448-.115.83-.329%201.15-.205.307-.47.513-.692.662-.109.072-.22.138-.313.195l-.006.004a6%206%200%200%200-.26.16%201%201%200%200%200-.276.245.75.75%200%200%201-1.248-.832c.184-.264.42-.489.692-.661q.154-.1.313-.195l.007-.004c.1-.061.182-.11.258-.161a1%201%200%200%200%20.277-.245C8.96%206.514%209%206.427%209%206.25a.61.61%200%200%200-.262-.525A1.27%201.27%200%200%200%208%205.5c-.369%200-.595.09-.74.187a1%201%200%200%200-.34.398M9%2011a1%201%200%201%201-2%200%201%201%200%200%201%202%200%22/%3E%3C/svg%3E');--md-admonition-icon--warning:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M6.457%201.047c.659-1.234%202.427-1.234%203.086%200l6.082%2011.378A1.75%201.75%200%200%201%2014.082%2015H1.918a1.75%201.75%200%200%201-1.543-2.575Zm1.763.707a.25.25%200%200%200-.44%200L1.698%2013.132a.25.25%200%200%200%20.22.368h12.164a.25.25%200%200%200%20.22-.368Zm.53%203.996v2.5a.75.75%200%200%201-1.5%200v-2.5a.75.75%200%200%201%201.5%200M9%2011a1%201%200%201%201-2%200%201%201%200%200%201%202%200%22/%3E%3C/svg%3E');--md-admonition-icon--failure:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M2.344%202.343za8%208%200%200%201%2011.314%2011.314A8.002%208.002%200%200%201%20.234%2010.089a8%208%200%200%201%202.11-7.746m1.06%2010.253a6.5%206.5%200%201%200%209.108-9.275%206.5%206.5%200%200%200-9.108%209.275M6.03%204.97%208%206.94l1.97-1.97a.749.749%200%200%201%201.275.326.75.75%200%200%201-.215.734L9.06%208l1.97%201.97a.749.749%200%200%201-.326%201.275.75.75%200%200%201-.734-.215L8%209.06l-1.97%201.97a.749.749%200%200%201-1.275-.326.75.75%200%200%201%20.215-.734L6.94%208%204.97%206.03a.75.75%200%200%201%20.018-1.042.75.75%200%200%201%201.042-.018%22/%3E%3C/svg%3E');--md-admonition-icon--danger:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M9.504.43a1.516%201.516%200%200%201%202.437%201.713L10.415%205.5h2.123c1.57%200%202.346%201.909%201.22%203.004l-7.34%207.142a1.25%201.25%200%200%201-.871.354h-.302a1.25%201.25%200%200%201-1.157-1.723L5.633%2010.5H3.462c-1.57%200-2.346-1.909-1.22-3.004zm1.047%201.074L3.286%208.571A.25.25%200%200%200%203.462%209H6.75a.75.75%200%200%201%20.694%201.034l-1.713%204.188%206.982-6.793A.25.25%200%200%200%2012.538%207H9.25a.75.75%200%200%201-.683-1.06l2.008-4.418.003-.006-.004-.009-.006-.006-.008-.001q-.005%200-.009.004%22/%3E%3C/svg%3E');--md-admonition-icon--bug:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M4.72.22a.75.75%200%200%201%201.06%200l1%20.999a3.5%203.5%200%200%201%202.441%200l.999-1a.748.748%200%200%201%201.265.332.75.75%200%200%201-.205.729l-.775.776c.616.63.995%201.493.995%202.444v.327q0%20.15-.025.292c.408.14.764.392%201.029.722l1.968-.787a.75.75%200%200%201%20.556%201.392L13%207.258V9h2.25a.75.75%200%200%201%200%201.5H13v.5q-.002.615-.141%201.186l2.17.868a.75.75%200%200%201-.557%201.392l-2.184-.873A5%205%200%200%201%208%2016a5%205%200%200%201-4.288-2.427l-2.183.873a.75.75%200%200%201-.558-1.392l2.17-.868A5%205%200%200%201%203%2011v-.5H.75a.75.75%200%200%201%200-1.5H3V7.258L.971%206.446a.75.75%200%200%201%20.558-1.392l1.967.787c.265-.33.62-.583%201.03-.722a1.7%201.7%200%200%201-.026-.292V4.5c0-.951.38-1.814.995-2.444L4.72%201.28a.75.75%200%200%201%200-1.06m.53%206.28a.75.75%200%200%200-.75.75V11a3.5%203.5%200%201%200%207%200V7.25a.75.75%200%200%200-.75-.75ZM6.173%205h3.654A.17.17%200%200%200%2010%204.827V4.5a2%202%200%201%200-4%200v.327c0%20.096.077.173.173.173%22/%3E%3C/svg%3E');--md-admonition-icon--example:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M5%205.782V2.5h-.25a.75.75%200%200%201%200-1.5h6.5a.75.75%200%200%201%200%201.5H11v3.282l3.666%205.76C15.619%2013.04%2014.543%2015%2012.767%2015H3.233c-1.776%200-2.852-1.96-1.899-3.458Zm-2.4%206.565a.75.75%200%200%200%20.633%201.153h9.534a.75.75%200%200%200%20.633-1.153L12.225%2010.5h-8.45ZM9.5%202.5h-3V6c0%20.143-.04.283-.117.403L4.73%209h6.54L9.617%206.403A.75.75%200%200%201%209.5%206Z%22/%3E%3C/svg%3E');--md-admonition-icon--quote:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M1.75%202.5h10.5a.75.75%200%200%201%200%201.5H1.75a.75.75%200%200%201%200-1.5m4%205h8.5a.75.75%200%200%201%200%201.5h-8.5a.75.75%200%200%201%200-1.5m0%205h8.5a.75.75%200%200%201%200%201.5h-8.5a.75.75%200%200%201%200-1.5M2.5%207.75v6a.75.75%200%200%201-1.5%200v-6a.75.75%200%200%201%201.5%200%22/%3E%3C/svg%3E');}</style><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../../assets/_mkdocstrings.css><link rel=stylesheet href=../../../stylesheets/extra.css><script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-H8C0CLZTWR"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-H8C0CLZTWR",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-H8C0CLZTWR",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script><script>"undefined"!=typeof __md_analytics&&__md_analytics()</script></head> <body dir=ltr> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#2025 class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <header class="md-header md-header--shadow md-header--lifted" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../../.. title="Marcelo Acosta Cavalero" class="md-header__button md-logo" aria-label="Marcelo Acosta Cavalero" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a4 4 0 0 1 4 4 4 4 0 0 1-4 4 4 4 0 0 1-4-4 4 4 0 0 1 4-4m0 2a2 2 0 0 0-2 2 2 2 0 0 0 2 2 2 2 0 0 0 2-2 2 2 0 0 0-2-2m-2 12c-.25 0-.46-.18-.5-.42l-.37-2.65c-.63-.25-1.17-.59-1.69-.99l-2.49 1.01c-.22.08-.49 0-.61-.22l-2-3.46a.493.493 0 0 1 .12-.64l2.11-1.66L4.5 12l.07-1-2.11-1.63a.493.493 0 0 1-.12-.64l2-3.46c.12-.22.39-.31.61-.22l2.49 1c.52-.39 1.06-.73 1.69-.98l.37-2.65c.04-.24.25-.42.5-.42h4c.25 0 .46.18.5.42l.37 2.65c.63.25 1.17.59 1.69.98l2.49-1c.22-.09.49 0 .61.22l2 3.46c.13.22.07.49-.12.64L19.43 11l.07 1-.07 1 2.11 1.63c.19.15.25.42.12.64l-2 3.46c-.12.22-.39.31-.61.22l-2.49-1c-.52.39-1.06.73-1.69.98l-.37 2.65c-.04.24-.25.42-.5.42zm1.25-18-.37 2.61c-1.2.25-2.26.89-3.03 1.78L5.44 7.35l-.75 1.3L6.8 10.2a5.55 5.55 0 0 0 0 3.6l-2.12 1.56.75 1.3 2.43-1.04c.77.88 1.82 1.52 3.01 1.76l.37 2.62h1.52l.37-2.61c1.19-.25 2.24-.89 3.01-1.77l2.43 1.04.75-1.3-2.12-1.55c.4-1.17.4-2.44 0-3.61l2.11-1.55-.75-1.3-2.41 1.04a5.42 5.42 0 0 0-3.03-1.77L12.75 4z"/></svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Marcelo Acosta Cavalero </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> 2025 </span> </div> </div> </div> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <a href=javascript:void(0) class="md-search__icon md-icon" title=Share aria-label=Share data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg> </a> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/marceloacosta title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </div> <div class=md-source__repository> Github </div> </a> </div> </nav> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../../.. class=md-tabs__link> Sobre mí </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=../../ class=md-tabs__link> Escritos </a> </li> <li class=md-tabs__item> <a href=https://calendly.com/macosta-zircon/ class=md-tabs__link> Contacto </a> </li> </ul> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../../.. title="Marcelo Acosta Cavalero" class="md-nav__button md-logo" aria-label="Marcelo Acosta Cavalero" data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a4 4 0 0 1 4 4 4 4 0 0 1-4 4 4 4 0 0 1-4-4 4 4 0 0 1 4-4m0 2a2 2 0 0 0-2 2 2 2 0 0 0 2 2 2 2 0 0 0 2-2 2 2 0 0 0-2-2m-2 12c-.25 0-.46-.18-.5-.42l-.37-2.65c-.63-.25-1.17-.59-1.69-.99l-2.49 1.01c-.22.08-.49 0-.61-.22l-2-3.46a.493.493 0 0 1 .12-.64l2.11-1.66L4.5 12l.07-1-2.11-1.63a.493.493 0 0 1-.12-.64l2-3.46c.12-.22.39-.31.61-.22l2.49 1c.52-.39 1.06-.73 1.69-.98l.37-2.65c.04-.24.25-.42.5-.42h4c.25 0 .46.18.5.42l.37 2.65c.63.25 1.17.59 1.69.98l2.49-1c.22-.09.49 0 .61.22l2 3.46c.13.22.07.49-.12.64L19.43 11l.07 1-.07 1 2.11 1.63c.19.15.25.42.12.64l-2 3.46c-.12.22-.39.31-.61.22l-2.49-1c-.52.39-1.06.73-1.69.98l-.37 2.65c-.04.24-.25.42-.5.42zm1.25-18-.37 2.61c-1.2.25-2.26.89-3.03 1.78L5.44 7.35l-.75 1.3L6.8 10.2a5.55 5.55 0 0 0 0 3.6l-2.12 1.56.75 1.3 2.43-1.04c.77.88 1.82 1.52 3.01 1.76l.37 2.62h1.52l.37-2.61c1.19-.25 2.24-.89 3.01-1.77l2.43 1.04.75-1.3-2.12-1.55c.4-1.17.4-2.44 0-3.61l2.11-1.55-.75-1.3-2.41 1.04a5.42 5.42 0 0 0-3.03-1.77L12.75 4z"/></svg> </a> Marcelo Acosta Cavalero </label> <div class=md-nav__source> <a href=https://github.com/marceloacosta title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </div> <div class=md-source__repository> Github </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../.. class=md-nav__link> <span class=md-ellipsis> Sobre mí </span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2 checked> <div class="md-nav__link md-nav__container"> <a href=../../ class="md-nav__link "> <span class=md-ellipsis> Escritos </span> </a> <label class="md-nav__link " for=__nav_2 id=__nav_2_label tabindex> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=true> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Escritos </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../2025/05/23/de-rag-b%C3%A1sico-a-avanzado/ class=md-nav__link> <span class=md-ellipsis> De RAG Básico a Avanzado </span> </a> </li> <li class=md-nav__item> <a href=../../2025/05/29/convierte-errores-404-en-engagement-en-11-pasos/ class=md-nav__link> <span class=md-ellipsis> Convierte errores 404 en engagement en 11 pasos </span> </a> </li> <li class=md-nav__item> <a href=../../2024/12/01/agentes-inteligentes/ class=md-nav__link> <span class=md-ellipsis> Agentes Inteligentes </span> </a> </li> <li class=md-nav__item> <a href=../../2025/01/09/escalamiento-responsable-de-ia-d%C3%B3nde-termina-la-responsabilidad-del-proveedor-y-d%C3%B3nde-empieza-la-tuya/ class=md-nav__link> <span class=md-ellipsis> Escalamiento Responsable de IA, Dónde termina la responsabilidad del proveedor y dónde empieza la tuya </span> </a> </li> <li class=md-nav__item> <a href=../../2025/01/09/evaluaciones-en-ia-lo-que-todos-dicen-hacer-y-pocos-hacen-bien/ class=md-nav__link> <span class=md-ellipsis> Evaluaciones en IA, Lo que todos dicen hacer y pocos hacen bien </span> </a> </li> <li class=md-nav__item> <a href=../../2025/01/08/y-ya-implementaste-ia-en-tu-empresa/ class=md-nav__link> <span class=md-ellipsis> ¿Y ya implementaste IA en tu empresa? </span> </a> </li> <li class=md-nav__item> <a href=../../2025/01/14/la-realidad-detr%C3%A1s-del-hype-programadores-e-ia/ class=md-nav__link> <span class=md-ellipsis> La realidad detrás del hype Programadores e IA </span> </a> </li> <li class=md-nav__item> <a href=../../2025/01/31/lo-que-tu-cerebro-pierde-cuando-delegas-la-comprensi%C3%B3n-a-la-ia/ class=md-nav__link> <span class=md-ellipsis> Lo que tu cerebro pierde cuando delegas la comprensión a la IA </span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_10 checked> <label class=md-nav__link for=__nav_2_10 id=__nav_2_10_label tabindex> <span class=md-ellipsis> Archive </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_10_label aria-expanded=true> <label class=md-nav__title for=__nav_2_10> <span class="md-nav__icon md-icon"></span> Archive </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> 2025 </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> 2025 </span> </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#convierte-errores-404-en-engagement-en-11-pasos class=md-nav__link> <span class=md-ellipsis> Convierte errores 404 en engagement en 11 pasos </span> </a> </li> <li class=md-nav__item> <a href=#de-rag-basico-a-avanzado-la-evolucion-de-sistemas-de-ia-con-conocimiento-empresarial class=md-nav__link> <span class=md-ellipsis> De RAG Básico a Avanzado: La Evolución de Sistemas de IA con Conocimiento Empresarial </span> </a> </li> <li class=md-nav__item> <a href=#la-trampa-del-conocimiento-instantaneo-lo-que-tu-cerebro-pierde-cuando-delegas-la-comprension-a-la-ia class=md-nav__link> <span class=md-ellipsis> La Trampa del Conocimiento Instantáneo: Lo que tu cerebro pierde cuando delegas la comprensión a la IA </span> </a> </li> <li class=md-nav__item> <a href=#programadores-ia-la-realidad-detras-del-hype class=md-nav__link> <span class=md-ellipsis> Programadores + IA: La realidad detrás del hype </span> </a> </li> <li class=md-nav__item> <a href=#escalamiento-responsable-de-ia-donde-termina-la-responsabilidad-del-proveedor-y-donde-empieza-la-tuya class=md-nav__link> <span class=md-ellipsis> Escalamiento Responsable de IA: Dónde termina la responsabilidad del proveedor y dónde empieza la tuya </span> </a> </li> <li class=md-nav__item> <a href=#evaluaciones-en-ia-lo-que-todos-dicen-hacer-y-pocos-hacen-bien class=md-nav__link> <span class=md-ellipsis> Evaluaciones en IA: Lo que todos dicen hacer y pocos hacen bien </span> </a> </li> <li class=md-nav__item> <a href=#y-ya-implementaste-ia-en-tu-empresa class=md-nav__link> <span class=md-ellipsis> ¿Y ya implementaste IA en tu empresa? </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../2024/ class=md-nav__link> <span class=md-ellipsis> 2024 </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_2_11> <label class=md-nav__link for=__nav_2_11 id=__nav_2_11_label tabindex> <span class=md-ellipsis> Categories </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_11_label aria-expanded=false> <label class=md-nav__title for=__nav_2_11> <span class="md-nav__icon md-icon"></span> Categories </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../category/tech-tutorial/ class=md-nav__link> <span class=md-ellipsis> Tech Tutorial </span> </a> </li> <li class=md-nav__item> <a href=../../category/web-development/ class=md-nav__link> <span class=md-ellipsis> Web Development </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=https://calendly.com/macosta-zircon/ class=md-nav__link> <span class=md-ellipsis> Contacto </span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#convierte-errores-404-en-engagement-en-11-pasos class=md-nav__link> <span class=md-ellipsis> Convierte errores 404 en engagement en 11 pasos </span> </a> </li> <li class=md-nav__item> <a href=#de-rag-basico-a-avanzado-la-evolucion-de-sistemas-de-ia-con-conocimiento-empresarial class=md-nav__link> <span class=md-ellipsis> De RAG Básico a Avanzado: La Evolución de Sistemas de IA con Conocimiento Empresarial </span> </a> </li> <li class=md-nav__item> <a href=#la-trampa-del-conocimiento-instantaneo-lo-que-tu-cerebro-pierde-cuando-delegas-la-comprension-a-la-ia class=md-nav__link> <span class=md-ellipsis> La Trampa del Conocimiento Instantáneo: Lo que tu cerebro pierde cuando delegas la comprensión a la IA </span> </a> </li> <li class=md-nav__item> <a href=#programadores-ia-la-realidad-detras-del-hype class=md-nav__link> <span class=md-ellipsis> Programadores + IA: La realidad detrás del hype </span> </a> </li> <li class=md-nav__item> <a href=#escalamiento-responsable-de-ia-donde-termina-la-responsabilidad-del-proveedor-y-donde-empieza-la-tuya class=md-nav__link> <span class=md-ellipsis> Escalamiento Responsable de IA: Dónde termina la responsabilidad del proveedor y dónde empieza la tuya </span> </a> </li> <li class=md-nav__item> <a href=#evaluaciones-en-ia-lo-que-todos-dicen-hacer-y-pocos-hacen-bien class=md-nav__link> <span class=md-ellipsis> Evaluaciones en IA: Lo que todos dicen hacer y pocos hacen bien </span> </a> </li> <li class=md-nav__item> <a href=#y-ya-implementaste-ia-en-tu-empresa class=md-nav__link> <span class=md-ellipsis> ¿Y ya implementaste IA en tu empresa? </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <div class=md-content__inner> <header class=md-typeset> <h1 id=2025>2025<a class=headerlink href=#2025 title="Permanent link">&para;</a></h1> </header> <article class="md-post md-post--excerpt"> <header class=md-post__header> <nav class="md-post__authors md-typeset"> <span class=md-author> <img src=https://github.com/marceloacosta.png alt="Marcelo Acosta Cavalero"> </span> </nav> <div class="md-post__meta md-meta"> <ul class=md-meta__list> <li class=md-meta__item> <time datetime="2025-05-29 00:00:00+00:00">2025/05/29</time></li> <li class=md-meta__item> in <a href=../../category/web-development/ class=md-meta__link>Web Development</a>, <a href=../../category/tech-tutorial/ class=md-meta__link>Tech Tutorial</a></li> <li class=md-meta__item> 4 min read </li> </ul> </div> </header> <div class="md-post__content md-typeset"> <h2 id=convierte-errores-404-en-engagement-en-11-pasos><a href=../../2025/05/29/convierte-errores-404-en-engagement-en-11-pasos/ class=toclink>Convierte errores 404 en engagement en 11 pasos</a></h2> <p>El <strong>DOOM CAPTCHA</strong> de Guillermo Rauch me inspiró a crear algo similar para las páginas 404 de mi blog. En lugar del típico <em>«Página no encontrada»</em>, ahora los usuarios pueden jugar DOOM y, al matar tres demonios, son redirigidos automáticamente a la portada.</p> <p>Para verlo entra a cualquier página que no exista en este blog, por ejemplo <a href=https://www.marcelops.com/pagina-que-no-existe>https://www.marcelops.com/pagina-que-no-existe</a></p> <p>Lo interesante no fue solo compilar un juego de 1993 para navegadores modernos, sino cómo tecnologías completamente diferentes —un generador de sitios estáticos, un compilador de C a WebAssembly y controles táctiles— se integraron en una solución coherente que cualquiera puede reproducir.</p> <h3 id=11-pasos-de-la-idea-a-la-produccion><a class=toclink href=../../2025/05/29/convierte-errores-404-en-engagement-en-11-pasos/#11-pasos-de-la-idea-a-la-produccion>11 pasos de la idea a la producción</a></h3> <h4 id=paso-1-preparar-el-terreno-con-mkdocs><a class=toclink href=../../2025/05/29/convierte-errores-404-en-engagement-en-11-pasos/#paso-1-preparar-el-terreno-con-mkdocs>Paso 1 – Preparar el terreno con MkDocs</a></h4> <p>MkDocs es un <strong>generador de sitios estáticos pensado para documentación</strong>, construido sobre Python. Al alojar mi blog allí, ya tenía un pipeline de construcción simple y sin servidores.</p> <p>Primero creo y activo un <em>virtualenv</em> para aislar dependencias, instalo <strong>Material for MkDocs</strong> —el tema que da el look &amp; feel— y declaro la carpeta <code>overrides</code> en <code>mkdocs.yml</code>. <code>overrides</code> actúa como una carpeta "shadow": cualquier archivo que pongas allí reemplaza al del tema por defecto. Finalmente, creo <code>docs/assets/doom404</code>, el directorio que servirá los binarios del juego como si fueran imágenes.</p> <h4 id=paso-2-disenar-la-nueva-404><a class=toclink href=../../2025/05/29/convierte-errores-404-en-engagement-en-11-pasos/#paso-2-disenar-la-nueva-404>Paso 2 – Diseñar la nueva 404</a></h4> <p>La plantilla <code>overrides/404.html</code> es donde sucede la magia. Un <code>&lt;canvas&gt;</code> ocupa todo el viewport; encima flota un pequeño HUD que muestra el progreso del jugador.</p> <p><em>¿Por qué un <code>&lt;canvas&gt;</code>?</em> Porque WebAssembly dibuja directamente en él usando WebGL; no hay capas intermedias de DOM.</p> <p>Dentro del HUD, incluyo el mensaje <em>«Mata 3 demonios para volver al blog»</em> y un contador que empieza en 0. El HTML apenas pesa unos kilobytes, pero le da a la página 404 el mismo dramatismo que la pantalla de inicio del DOOM original.</p> <h4 id=paso-3-compilar-doom-para-el-navegador><a class=toclink href=../../2025/05/29/convierte-errores-404-en-engagement-en-11-pasos/#paso-3-compilar-doom-para-el-navegador>Paso 3 – Compilar DOOM para el navegador</a></h4> <p>Aquí entra <strong>Emscripten</strong>, el compilador que convierte código C/C++ en WebAssembly.</p> <p>Clono un fork de DOOM que ya compila fuera de DOS, descargo el <strong>WAD shareware</strong> (los gráficos y niveles) e instalo Emscripten. El <em>hack</em> clave es sustituir <code>SDL_SWSURFACE</code> por <code>0</code> en la llamada a <code>SDL_SetVideoMode</code>; con eso evito que SDL intente bloquear la superficie de vídeo —una operación que no existe en el navegador.</p> <p>Ejecutar <code>build_doom.sh</code> produce tres archivos: <code>index.js</code> (código <em>glue</em> que arranca el runtime), <code>index.wasm</code> (el binario con el motor) y <code>index.data</code> (texturas y audio). Copiarlos a <code>docs/assets/doom404</code> basta para que MkDocs los sirva en la build final.</p> <h4 id=paso-4-contar-demonios-desde-javascript><a class=toclink href=../../2025/05/29/convierte-errores-404-en-engagement-en-11-pasos/#paso-4-contar-demonios-desde-javascript>Paso 4 – Contar demonios desde JavaScript</a></h4> <p>El motor original no sabe nada de JavaScript, así que modifico la función de muerte de cada enemigo con <code>EM_ASM</code>. Esta macro de Emscripten permite <strong>inyectar instrucciones JS</strong> dentro del código C. Cada vez que un enemigo pasa a estado <code>dead</code>, JS dispara <code>window.onEnemyKilled()</code>.</p> <p>En el navegador llevo la cuenta con una variable <code>kills</code>. Cuando llega a 3, hago un <code>setTimeout</code> de un segundo y redirijo a <code>/</code>. Ese pequeño retraso deja ver la animación de victoria y mejora la experiencia.</p> <h4 id=paso-5-traducir-la-interfaz><a class=toclink href=../../2025/05/29/convierte-errores-404-en-engagement-en-11-pasos/#paso-5-traducir-la-interfaz>Paso 5 – Traducir la interfaz</a></h4> <p>El juego sigue en inglés, pero el HUD es la cara visible del proyecto, así que traduzco los textos a español. Extraigo los strings a constantes para poder añadir otros idiomas en el futuro.</p> <h4 id=paso-6-hacerlo-responsivo><a class=toclink href=../../2025/05/29/convierte-errores-404-en-engagement-en-11-pasos/#paso-6-hacerlo-responsivo>Paso 6 – Hacerlo responsivo</a></h4> <p>Muchos tutoriales olvidan esto: en móviles, un canvas sin ajustes puede desbordar el viewport y romper la UI. Con una sola media‑query reduzco padding y fuente del HUD cuando la pantalla es menor a 768 px. Nada de <em>frameworks</em> pesados, puro CSS.</p> <h4 id=paso-7-anadir-controles-tactiles><a class=toclink href=../../2025/05/29/convierte-errores-404-en-engagement-en-11-pasos/#paso-7-anadir-controles-tactiles>Paso 7 – Añadir controles táctiles</a></h4> <p>DOOM usa teclado; los móviles no. Para solucionar esto creo un <strong>D‑pad SVG</strong> y dos botones circulares. Cada botón sintetiza eventos <code>keydown</code> y <code>keyup</code> con el <em>keycode</em> correcto (<code>37–40</code> para flechas, <code>17</code> para Ctrl, <code>32</code> para Space). Así no toco el motor; simplemente lo engaño haciéndole creer que alguien pulsa teclas físicas.</p> <h4 id=paso-8-pulir-la-experiencia-movil><a class=toclink href=../../2025/05/29/convierte-errores-404-en-engagement-en-11-pasos/#paso-8-pulir-la-experiencia-movil>Paso 8 – Pulir la experiencia móvil</a></h4> <p>El HUD es útil, pero si ocupa un tercio de pantalla arruina la inmersión. Le bajo la opacidad, le pongo fondo semitransparente y lo limito a 200 px de ancho. Además oculto totalmente el D‑pad cuando <code>window.matchMedia('(pointer:fine)')</code> indica un dispositivo de escritorio.</p> <h4 id=paso-9-ordenar-los-archivos><a class=toclink href=../../2025/05/29/convierte-errores-404-en-engagement-en-11-pasos/#paso-9-ordenar-los-archivos>Paso 9 – Ordenar los archivos</a></h4> <p>Si alguien clona el repo debería entenderlo en 30 segundos. Por eso mantengo la raíz limpia: <code>mkdocs.yml</code>, un solo script de compilación y la carpeta <code>overrides</code>. Todo lo relativo al juego vive bajo <code>docs/assets/doom404</code>.</p> <h4 id=paso-10-automatizar-el-despliegue><a class=toclink href=../../2025/05/29/convierte-errores-404-en-engagement-en-11-pasos/#paso-10-automatizar-el-despliegue>Paso 10 – Automatizar el despliegue</a></h4> <p>GitHub Actions corre en cada <em>push</em>: instala dependencias, ejecuta <code>mkdocs build</code> y sube el contenido de <code>site</code> a GitHub Pages. El archivo <code>.data</code> pesa 4 MB; para evitar errores de <em>buffer</em> aumento <code>http.postBuffer</code> a 512 MB una sola vez.</p> <h4 id=paso-11-resolver-los-tropiezos-habituales><a class=toclink href=../../2025/05/29/convierte-errores-404-en-engagement-en-11-pasos/#paso-11-resolver-los-tropiezos-habituales>Paso 11 – Resolver los tropiezos habituales</a></h4> <ul> <li><strong>Pantalla negra</strong>: si ves solo un canvas vacío, casi siempre es el parche SDL perdido. Vuelve al Paso 3.</li> <li><strong>Push interrumpido</strong>: Git aborta al traspasar 50 MB de datos. Sube el límite con <code>git config http.postBuffer 524288000</code>.</li> <li><strong>HUD invasivo</strong>: si en escritorio el HUD tapa la acción, revisa la media‑query del Paso 6; probablemente el tamaño mínimo no se aplica porque el viewport es mayor que 768 px.</li> </ul> <p>Este DOOM 404 convierte un error en una micro‑experiencia que engancha a los visitantes de tu web. Con Google Analytics se puede demostrar el impacto en el tiempo de permanencia en la página y la tasa de rebote, consiguiendo un mayor engagement y conversión.</p> <p><em>Si necesitas ayuda para que tu equipo combine tecnologías o integre IA de forma práctica en su trabajo, contáctame y lo revisamos juntos.</em></p> </div> </article> <article class="md-post md-post--excerpt"> <header class=md-post__header> <div class="md-post__meta md-meta"> <ul class=md-meta__list> <li class=md-meta__item> <time datetime="2025-05-23 00:00:00+00:00">2025/05/23</time></li> <li class=md-meta__item> 22 min read </li> </ul> </div> </header> <div class="md-post__content md-typeset"> <h2 id=de-rag-basico-a-avanzado-la-evolucion-de-sistemas-de-ia-con-conocimiento-empresarial><a href=../../2025/05/23/de-rag-b%C3%A1sico-a-avanzado/ class=toclink>De RAG Básico a Avanzado: La Evolución de Sistemas de IA con Conocimiento Empresarial</a></h2> <p>¿Por qué algunos sistemas RAG (Retrieval-Augmented Generation) entregan respuestas precisas y contextualizadas mientras otros devuelven información irrelevante o incluso inventada? La diferencia no está solo en la calidad de los datos o en el modelo de lenguaje utilizado.</p> <p>Tras analizar numerosas implementaciones RAG en entornos empresariales, he identificado que existe una escala de madurez claramente definida. Los sistemas que realmente generan valor no se limitan a conectar un LLM con una base de datos vectorial - avanzan a través de niveles de sofisticación que todo CTO debería conocer en profundidad para mantenerse competitivo en 2025.</p> <p>En este artículo, te revelaré los 9 (en realidad 10) niveles de madurez RAG que marcan la diferencia entre sistemas que frustran a los usuarios y aquellos que transforman operaciones de negocio. Si estás considerando invertir en esta tecnología o ya tienes un sistema básico funcionando, entender esta progresión te ahorrará meses de desarrollo y posiblemente cientos de miles en costos evitables.</p> <h3 id=nivel-0-el-rag-minimo-viable><a class=toclink href=../../2025/05/23/de-rag-b%C3%A1sico-a-avanzado/#nivel-0-el-rag-minimo-viable>Nivel 0: El RAG Mínimo Viable</a></h3> <p>Comencemos con lo que yo llamo "RAG Mínimo Viable" - la implementación más básica que técnicamente funciona, pero apenas rasca la superficie de lo que es posible. Este es el código que verás en tutoriales y demostraciones rápidas:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-1-1><a id=__codelineno-1-1 name=__codelineno-1-1 href=#__codelineno-1-1></a><span class=kn>from</span><span class=w> </span><span class=nn>sentence_transformers</span><span class=w> </span><span class=kn>import</span> <span class=n>SentenceTransformer</span>
</span><span id=__span-1-2><a id=__codelineno-1-2 name=__codelineno-1-2 href=#__codelineno-1-2></a><span class=kn>import</span><span class=w> </span><span class=nn>faiss</span><span class=o>,</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
</span><span id=__span-1-3><a id=__codelineno-1-3 name=__codelineno-1-3 href=#__codelineno-1-3></a><span class=kn>import</span><span class=w> </span><span class=nn>os</span>
</span><span id=__span-1-4><a id=__codelineno-1-4 name=__codelineno-1-4 href=#__codelineno-1-4></a><span class=kn>from</span><span class=w> </span><span class=nn>pathlib</span><span class=w> </span><span class=kn>import</span> <span class=n>Path</span>
</span><span id=__span-1-5><a id=__codelineno-1-5 name=__codelineno-1-5 href=#__codelineno-1-5></a>
</span><span id=__span-1-6><a id=__codelineno-1-6 name=__codelineno-1-6 href=#__codelineno-1-6></a><span class=k>def</span><span class=w> </span><span class=nf>obtener_archivos_de_carpeta</span><span class=p>(</span><span class=n>ruta</span><span class=p>,</span> <span class=n>extensiones</span><span class=o>=</span><span class=p>(</span><span class=s2>&quot;.txt&quot;</span><span class=p>,</span> <span class=s2>&quot;.md&quot;</span><span class=p>)):</span>
</span><span id=__span-1-7><a id=__codelineno-1-7 name=__codelineno-1-7 href=#__codelineno-1-7></a>    <span class=n>carpeta</span> <span class=o>=</span> <span class=n>Path</span><span class=p>(</span><span class=n>ruta</span><span class=p>)</span>
</span><span id=__span-1-8><a id=__codelineno-1-8 name=__codelineno-1-8 href=#__codelineno-1-8></a>    <span class=k>if</span> <span class=ow>not</span> <span class=n>carpeta</span><span class=o>.</span><span class=n>exists</span><span class=p>():</span>
</span><span id=__span-1-9><a id=__codelineno-1-9 name=__codelineno-1-9 href=#__codelineno-1-9></a>        <span class=k>raise</span> <span class=ne>FileNotFoundError</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;La carpeta </span><span class=si>{</span><span class=n>ruta</span><span class=si>}</span><span class=s2> no existe&quot;</span><span class=p>)</span>
</span><span id=__span-1-10><a id=__codelineno-1-10 name=__codelineno-1-10 href=#__codelineno-1-10></a>    <span class=k>return</span> <span class=p>[</span><span class=nb>str</span><span class=p>(</span><span class=n>f</span><span class=p>)</span> <span class=k>for</span> <span class=n>f</span> <span class=ow>in</span> <span class=n>carpeta</span><span class=o>.</span><span class=n>iterdir</span><span class=p>()</span>
</span><span id=__span-1-11><a id=__codelineno-1-11 name=__codelineno-1-11 href=#__codelineno-1-11></a>            <span class=k>if</span> <span class=n>f</span><span class=o>.</span><span class=n>is_file</span><span class=p>()</span> <span class=ow>and</span> <span class=n>f</span><span class=o>.</span><span class=n>suffix</span><span class=o>.</span><span class=n>lower</span><span class=p>()</span> <span class=ow>in</span> <span class=n>extensiones</span><span class=p>]</span>
</span><span id=__span-1-12><a id=__codelineno-1-12 name=__codelineno-1-12 href=#__codelineno-1-12></a>
</span><span id=__span-1-13><a id=__codelineno-1-13 name=__codelineno-1-13 href=#__codelineno-1-13></a><span class=c1># 1. Modelo de embeddings</span>
</span><span id=__span-1-14><a id=__codelineno-1-14 name=__codelineno-1-14 href=#__codelineno-1-14></a><span class=n>embedder</span> <span class=o>=</span> <span class=n>SentenceTransformer</span><span class=p>(</span><span class=s1>&#39;all-MiniLM-L6-v2&#39;</span><span class=p>)</span>
</span><span id=__span-1-15><a id=__codelineno-1-15 name=__codelineno-1-15 href=#__codelineno-1-15></a>
</span><span id=__span-1-16><a id=__codelineno-1-16 name=__codelineno-1-16 href=#__codelineno-1-16></a><span class=c1># 2. Cargar documentos de la carpeta</span>
</span><span id=__span-1-17><a id=__codelineno-1-17 name=__codelineno-1-17 href=#__codelineno-1-17></a><span class=n>docs</span> <span class=o>=</span> <span class=p>[</span><span class=nb>open</span><span class=p>(</span><span class=n>f</span><span class=p>,</span> <span class=n>encoding</span><span class=o>=</span><span class=s2>&quot;utf-8&quot;</span><span class=p>)</span><span class=o>.</span><span class=n>read</span><span class=p>()</span> <span class=k>for</span> <span class=n>f</span> <span class=ow>in</span> <span class=n>obtener_archivos_de_carpeta</span><span class=p>(</span><span class=s2>&quot;/content/knowledge_base&quot;</span><span class=p>)]</span>
</span><span id=__span-1-18><a id=__codelineno-1-18 name=__codelineno-1-18 href=#__codelineno-1-18></a>
</span><span id=__span-1-19><a id=__codelineno-1-19 name=__codelineno-1-19 href=#__codelineno-1-19></a><span class=c1># 3. Generar embeddings e indexar</span>
</span><span id=__span-1-20><a id=__codelineno-1-20 name=__codelineno-1-20 href=#__codelineno-1-20></a><span class=n>doc_embeddings</span> <span class=o>=</span> <span class=n>embedder</span><span class=o>.</span><span class=n>encode</span><span class=p>(</span><span class=n>docs</span><span class=p>,</span> <span class=n>convert_to_numpy</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-1-21><a id=__codelineno-1-21 name=__codelineno-1-21 href=#__codelineno-1-21></a><span class=n>index</span> <span class=o>=</span> <span class=n>faiss</span><span class=o>.</span><span class=n>IndexFlatIP</span><span class=p>(</span><span class=n>doc_embeddings</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>1</span><span class=p>])</span>
</span><span id=__span-1-22><a id=__codelineno-1-22 name=__codelineno-1-22 href=#__codelineno-1-22></a><span class=n>index</span><span class=o>.</span><span class=n>add</span><span class=p>(</span><span class=n>doc_embeddings</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=s1>&#39;float32&#39;</span><span class=p>))</span>
</span><span id=__span-1-23><a id=__codelineno-1-23 name=__codelineno-1-23 href=#__codelineno-1-23></a>
</span><span id=__span-1-24><a id=__codelineno-1-24 name=__codelineno-1-24 href=#__codelineno-1-24></a><span class=c1># 4. Función de búsqueda</span>
</span><span id=__span-1-25><a id=__codelineno-1-25 name=__codelineno-1-25 href=#__codelineno-1-25></a><span class=k>def</span><span class=w> </span><span class=nf>buscar_documentos</span><span class=p>(</span><span class=n>pregunta</span><span class=p>,</span> <span class=n>k</span><span class=o>=</span><span class=mi>5</span><span class=p>):</span>
</span><span id=__span-1-26><a id=__codelineno-1-26 name=__codelineno-1-26 href=#__codelineno-1-26></a>    <span class=n>vec</span> <span class=o>=</span> <span class=n>embedder</span><span class=o>.</span><span class=n>encode</span><span class=p>([</span><span class=n>pregunta</span><span class=p>],</span> <span class=n>convert_to_numpy</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=s1>&#39;float32&#39;</span><span class=p>)</span>
</span><span id=__span-1-27><a id=__codelineno-1-27 name=__codelineno-1-27 href=#__codelineno-1-27></a>    <span class=n>D</span><span class=p>,</span> <span class=n>I</span> <span class=o>=</span> <span class=n>index</span><span class=o>.</span><span class=n>search</span><span class=p>(</span><span class=n>vec</span><span class=p>,</span> <span class=n>k</span><span class=p>)</span>
</span><span id=__span-1-28><a id=__codelineno-1-28 name=__codelineno-1-28 href=#__codelineno-1-28></a>    <span class=k>return</span> <span class=p>[</span><span class=n>docs</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=n>I</span><span class=p>[</span><span class=mi>0</span><span class=p>]]</span>
</span><span id=__span-1-29><a id=__codelineno-1-29 name=__codelineno-1-29 href=#__codelineno-1-29></a>
</span><span id=__span-1-30><a id=__codelineno-1-30 name=__codelineno-1-30 href=#__codelineno-1-30></a><span class=c1># 5. Ejemplo</span>
</span><span id=__span-1-31><a id=__codelineno-1-31 name=__codelineno-1-31 href=#__codelineno-1-31></a><span class=n>pregunta</span> <span class=o>=</span> <span class=s2>&quot;puedo alargar mi viaje para tomar vacaciones si estoy haciendo un curso de la empresa en el exterior?&quot;</span>
</span><span id=__span-1-32><a id=__codelineno-1-32 name=__codelineno-1-32 href=#__codelineno-1-32></a><span class=n>fragmentos</span> <span class=o>=</span> <span class=n>buscar_documentos</span><span class=p>(</span><span class=n>pregunta</span><span class=p>,</span> <span class=n>k</span><span class=o>=</span><span class=mi>3</span><span class=p>)</span>
</span><span id=__span-1-33><a id=__codelineno-1-33 name=__codelineno-1-33 href=#__codelineno-1-33></a>
</span><span id=__span-1-34><a id=__codelineno-1-34 name=__codelineno-1-34 href=#__codelineno-1-34></a><span class=n>prompt</span> <span class=o>=</span> <span class=s2>&quot;Usa la siguiente información para responder la pregunta.</span><span class=se>\n\n</span><span class=s2>&quot;</span>
</span><span id=__span-1-35><a id=__codelineno-1-35 name=__codelineno-1-35 href=#__codelineno-1-35></a><span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>frag</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>fragmentos</span><span class=p>,</span> <span class=mi>1</span><span class=p>):</span>
</span><span id=__span-1-36><a id=__codelineno-1-36 name=__codelineno-1-36 href=#__codelineno-1-36></a>    <span class=n>prompt</span> <span class=o>+=</span> <span class=sa>f</span><span class=s2>&quot;[Documento </span><span class=si>{</span><span class=n>i</span><span class=si>}</span><span class=s2>]: </span><span class=si>{</span><span class=n>frag</span><span class=si>}</span><span class=se>\n\n</span><span class=s2>&quot;</span>
</span><span id=__span-1-37><a id=__codelineno-1-37 name=__codelineno-1-37 href=#__codelineno-1-37></a><span class=n>prompt</span> <span class=o>+=</span> <span class=sa>f</span><span class=s2>&quot;Pregunta: </span><span class=si>{</span><span class=n>pregunta</span><span class=si>}</span><span class=se>\n</span><span class=s2>Respuesta:&quot;</span>
</span></code></pre></div> <p>Este código puede implementarse en minutos y funciona para casos simples. Carga documentos de texto, genera embeddings con un modelo preentrenado, crea un índice vectorial en memoria y permite buscar documentos similares a una pregunta. Luego construye un prompt que podría enviarse a cualquier LLM.</p> <p>Sin embargo, esta implementación tiene serias limitaciones:</p> <ul> <li>No segmenta adecuadamente los documentos largos</li> <li>Utiliza un modelo de embeddings genérico que no está optimizado para tu dominio</li> <li>No maneja documentos con formatos complejos (PDF, Excel, imágenes)</li> <li>La búsqueda es puramente vectorial, sin capacidad de filtrado</li> <li>No hay mecanismos para evitar alucinaciones del LLM</li> <li>Carece de observabilidad y capacidad de mejora continua</li> </ul> <p>Esta implementación básica puede ser suficiente para una prueba de concepto, pero en un entorno empresarial real, rápidamente se vuelve insuficiente. Aquí es donde comienza el verdadero viaje de madurez RAG.</p> <h3 id=nivel-1-fundamentos-de-una-aplicacion-rag-productiva><a class=toclink href=../../2025/05/23/de-rag-b%C3%A1sico-a-avanzado/#nivel-1-fundamentos-de-una-aplicacion-rag-productiva>Nivel 1: Fundamentos de una aplicación RAG productiva</a></h3> <p>El Nivel 1 establece la base sólida para un sistema RAG funcional en entorno profesional. A diferencia del Nivel 0, aquí ya consideramos aspectos clave para una implementación que pueda manejar casos de uso empresariales reales.</p> <h4 id=que-incluye-este-nivel><a class=toclink href=../../2025/05/23/de-rag-b%C3%A1sico-a-avanzado/#que-incluye-este-nivel>¿Qué incluye este nivel?</a></h4> <ol> <li> <p><strong>Procesamiento y segmentación inteligente de texto</strong>: Dividimos documentos largos en fragmentos manejables (chunks) de aproximadamente 500 tokens, con técnicas de solapamiento para preservar el contexto entre fragmentos. Esto es crucial para que la información no quede fragmentada artificialmente.</p> </li> <li> <p><strong>Selección consciente de modelos de embeddings</strong>: En 2025, ya no basta con usar el primer modelo de embeddings que encontremos. Evaluamos modelos específicos como los de OpenAI, Cohere o HuggingFace optimizados para búsqueda semántica, considerando dimensionalidad, rendimiento y costo.</p> </li> <li> <p><strong>Almacenamiento vectorial escalable</strong>: Sustituimos la solución en memoria (FAISS) por bases de datos vectoriales diseñadas para producción como Pinecone, Weaviate, Milvus o soluciones cloud como Amazon OpenSearch con capacidades vectoriales.</p> </li> <li> <p><strong>Pipeline estructurado de ingesta</strong>: Implementamos un flujo que extrae texto de diversos formatos (PDF, Word, HTML), los procesa, segmenta y vectoriza de forma sistemática, manteniendo metadatos críticos como origen, fecha o autor.</p> </li> <li> <p><strong>Gestión básica de prompts</strong>: Diseñamos templates de prompts que instruyen claramente al LLM sobre cómo utilizar el contexto recuperado, evitando alucinaciones básicas y formateando adecuadamente la respuesta.</p> </li> </ol> <h4 id=ejemplo-de-mejora-respecto-al-nivel-0><a class=toclink href=../../2025/05/23/de-rag-b%C3%A1sico-a-avanzado/#ejemplo-de-mejora-respecto-al-nivel-0>Ejemplo de mejora respecto al Nivel 0</a></h4> <p>En lugar del enfoque monolítico del Nivel 0, ahora separamos claramente:</p> <ul> <li>Un pipeline de ingesta que procesa documentos por lotes</li> <li>Un servicio de búsqueda vectorial optimizado</li> <li>Un servicio de generación que conecta con el LLM elegido</li> </ul> <p>El Nivel 1 representa el mínimo aceptable para un despliegue inicial en producción. Sin embargo, todavía carece de optimizaciones críticas en búsqueda, monitoreo y evaluación de calidad.</p> <h4 id=tecnologias-recomendadas><a class=toclink href=../../2025/05/23/de-rag-b%C3%A1sico-a-avanzado/#tecnologias-recomendadas>Tecnologías recomendadas</a></h4> <ul> <li><strong>Bases vectoriales</strong>: Amazon OpenSearch Serverless, Pinecone, Weaviate</li> <li><strong>Modelos de embeddings</strong>: OpenAI text-embedding-3, Cohere embed-multilingual, HuggingFace E5 o BERT especializados</li> <li><strong>LLMs</strong>: GPT-4 Turbo, Claude 3 Opus, o modelos desplegados en AWS Bedrock</li> </ul> <p>La arquitectura del Nivel 1 ya permite manejar cientos de documentos corporativos y responder consultas básicas con contexto relevante. Sin embargo, las limitaciones aparecerán rápidamente cuando los usuarios comiencen a hacer preguntas más complejas o cuando el volumen de datos crezca significativamente.</p> <h3 id=nivel-2-procesamiento-estructurado-y-busqueda-optimizada><a class=toclink href=../../2025/05/23/de-rag-b%C3%A1sico-a-avanzado/#nivel-2-procesamiento-estructurado-y-busqueda-optimizada>Nivel 2: Procesamiento estructurado y búsqueda optimizada</a></h3> <p>El Nivel 2 perfecciona significativamente los tres pilares del sistema RAG: el procesamiento de datos, la búsqueda de información relevante y la generación de respuestas. Aquí es donde las implementaciones comienzan a diferenciarse de las soluciones básicas.</p> <h4 id=procesamiento-de-datos-mejorado><a class=toclink href=../../2025/05/23/de-rag-b%C3%A1sico-a-avanzado/#procesamiento-de-datos-mejorado>Procesamiento de datos mejorado</a></h4> <p>En este nivel, implementamos:</p> <ul> <li> <p><strong>Procesamiento asíncrono y paralelo</strong>: Utilizamos frameworks como Python asyncio o sistemas distribuidos (AWS Lambda, Dask, Ray) para procesar grandes volúmenes de documentos sin saturar recursos.</p> </li> <li> <p><strong>Segmentación inteligente por contexto</strong>: En lugar de dividir por número fijo de tokens, segmentamos por unidades lógicas (párrafos, secciones) preservando la coherencia semántica.</p> </li> <li> <p><strong>Mecanismos de tolerancia a fallos</strong>: Implementamos reintentos exponenciales para llamadas a APIs de embeddings y registramos documentos problemáticos para reprocesamiento posterior.</p> </li> </ul> <h4 id=busqueda-avanzada-con-ranking-hibrido><a class=toclink href=../../2025/05/23/de-rag-b%C3%A1sico-a-avanzado/#busqueda-avanzada-con-ranking-hibrido>Búsqueda avanzada con ranking híbrido</a></h4> <p>La verdadera evolución ocurre en la fase de recuperación:</p> <ul> <li> <p><strong>Reranking con modelos especializados</strong>: Aplicamos un segundo modelo (como Cohere Rerank o CrossEncoders) para reordenar los resultados iniciales, mejorando dramáticamente la precisión.</p> </li> <li> <p><strong>Expansión y reescritura de consultas</strong>: Utilizamos LLMs ligeros para reformular la pregunta del usuario, añadiendo términos relacionados y contexto. Por ejemplo, transformamos "¿precio del plan?" en "¿Cuál es el precio actual del plan empresarial en 2025?".</p> </li> <li> <p><strong>Búsquedas híbridas paralelas</strong>: Combinamos búsqueda vectorial con búsqueda léxica tradicional (keywords), ejecutándolas simultáneamente y fusionando resultados para mayor cobertura.</p> </li> </ul> <h4 id=generacion-de-respuestas-estructuradas><a class=toclink href=../../2025/05/23/de-rag-b%C3%A1sico-a-avanzado/#generacion-de-respuestas-estructuradas>Generación de respuestas estructuradas</a></h4> <p>La forma en que presentamos la información también se sofistica:</p> <ul> <li> <p><strong>Citación de fuentes</strong>: Incluimos referencias explícitas a los documentos origen, aumentando la confiabilidad y verificabilidad. Por ejemplo: "Según la Política de Viajes (2025), los empleados pueden extender su estancia pagando la diferencia de hospedaje".</p> </li> <li> <p><strong>Respuestas con formato estructurado</strong>: Generamos salidas en formato JSON o estructurado que separa claramente la respuesta principal, fuentes consultadas y posibles preguntas de seguimiento.</p> </li> <li> <p><strong>Streaming de respuestas</strong>: Implementamos generación en tiempo real, mostrando la respuesta mientras se va creando, mejorando significativamente la experiencia de usuario al reducir la percepción de espera.</p> </li> </ul> <h4 id=impacto-empresarial-del-nivel-2><a class=toclink href=../../2025/05/23/de-rag-b%C3%A1sico-a-avanzado/#impacto-empresarial-del-nivel-2>Impacto empresarial del Nivel 2</a></h4> <p>El Nivel 2 representa un salto cualitativo en la utilidad del sistema. Los usuarios reciben respuestas más precisas, con contexto relevante y en un formato verificable. La confianza en el sistema aumenta notablemente cuando las respuestas citan correctamente las fuentes internas.</p> <p>Sin embargo, aunque el sistema funciona bien, todavía opera como una "caja negra": no tenemos visibilidad sobre su desempeño interno ni mecanismos para mejorarlo sistemáticamente. Esto nos lleva al siguiente nivel de madurez.</p> <h3 id=nivel-3-observabilidad-entendiendo-el-comportamiento-del-sistema><a class=toclink href=../../2025/05/23/de-rag-b%C3%A1sico-a-avanzado/#nivel-3-observabilidad-entendiendo-el-comportamiento-del-sistema>Nivel 3: Observabilidad - Entendiendo el comportamiento del sistema</a></h3> <p>La principal diferencia entre un sistema RAG experimental y uno de producción es la capacidad de observar, medir y entender su funcionamiento interno. El Nivel 3 se enfoca en instrumentar cada componente para generar visibilidad completa.</p> <h4 id=instrumentacion-y-logging-extensivo><a class=toclink href=../../2025/05/23/de-rag-b%C3%A1sico-a-avanzado/#instrumentacion-y-logging-extensivo>Instrumentación y logging extensivo</a></h4> <p>En este nivel implementamos:</p> <ul> <li> <p><strong>Registro detallado de consultas</strong>: Almacenamos tanto la pregunta original del usuario como cualquier reformulación generada por el sistema. Esto permite identificar patrones de consulta y problemas de interpretación.</p> </li> <li> <p><strong>Trazabilidad de documentos</strong>: Registramos qué documentos fueron recuperados para cada consulta y cuáles fueron efectivamente citados en la respuesta final. La diferencia entre ambos conjuntos revela la calidad del retrieval.</p> </li> <li> <p><strong>Métricas de similitud y confianza</strong>: Capturamos los scores de similitud vectorial y del reranker para cada fragmento recuperado. Valores consistentemente bajos (por ejemplo, &lt;0.3) indican vacíos en la base de conocimiento.</p> </li> <li> <p><strong>Latencias detalladas</strong>: Medimos el tiempo de ejecución de cada componente (embedding, búsqueda, generación) para identificar cuellos de botella y optimizar rendimiento.</p> </li> <li> <p><strong>Metadatos contextuales</strong>: Registramos información sobre el usuario, departamento, dispositivo y contexto de la consulta, permitiendo análisis segmentados de uso y calidad.</p> </li> </ul> <h4 id=herramientas-de-observabilidad-llm><a class=toclink href=../../2025/05/23/de-rag-b%C3%A1sico-a-avanzado/#herramientas-de-observabilidad-llm>Herramientas de observabilidad LLM</a></h4> <p>El ecosistema de herramientas para monitorear aplicaciones basadas en LLM ha madurado significativamente:</p> <ul> <li> <p><strong>Langfuse</strong>: Plataforma open-source que visualiza cada paso del flujo RAG, mostrando prompts, resultados intermedios y métricas agregadas como costo por consulta.</p> </li> <li> <p><strong>LangSmith</strong>: Servicio de los creadores de LangChain que permite agrupar ejecuciones en proyectos, analizar trazas completas e incorporar feedback de usuarios.</p> </li> <li> <p><strong>Dashboards personalizados</strong>: Muchas organizaciones desarrollan visualizaciones específicas para sus casos de uso, integrando datos de observabilidad RAG con métricas de negocio.</p> </li> </ul> <h4 id=beneficios-de-la-observabilidad-para-decisiones-ejecutivas><a class=toclink href=../../2025/05/23/de-rag-b%C3%A1sico-a-avanzado/#beneficios-de-la-observabilidad-para-decisiones-ejecutivas>Beneficios de la observabilidad para decisiones ejecutivas</a></h4> <p>La observabilidad transforma la gestión del sistema RAG:</p> <ul> <li> <p><strong>Detección temprana de problemas</strong>: Identificar consultas con baja calidad de respuesta antes de que los usuarios se quejen.</p> </li> <li> <p><strong>Priorización basada en datos</strong>: Descubrir qué tipos de preguntas son más frecuentes pero tienen peor desempeño, orientando mejoras.</p> </li> <li> <p><strong>Justificación de inversiones</strong>: Demostrar el ROI del sistema con métricas concretas de uso, calidad y ahorro de tiempo.</p> </li> <li> <p><strong>Gestión de costos</strong>: Monitorear consumo de tokens y llamadas a APIs externas, optimizando el balance costo-calidad.</p> </li> </ul> <h4 id=caso-practico-descubriendo-vacios-de-conocimiento><a class=toclink href=../../2025/05/23/de-rag-b%C3%A1sico-a-avanzado/#caso-practico-descubriendo-vacios-de-conocimiento>Caso práctico: Descubriendo vacíos de conocimiento</a></h4> <p>Con un sistema de Nivel 3, podemos identificar patrones reveladores. Por ejemplo, al analizar los logs podríamos descubrir que todas las preguntas sobre "políticas de teletrabajo 2025" tienen scores de similitud muy bajos (≈0.15). Esto indica inmediatamente que nuestro sistema carece de documentación actualizada sobre este tema, permitiéndonos priorizar la incorporación de esa información.</p> <p>La observabilidad no es un lujo sino una necesidad para sistemas RAG empresariales. Sin ella, operamos a ciegas, sin capacidad de mejorar sistemáticamente ni de demostrar el valor generado.</p> <h3 id=nivel-4-evaluacion-de-calidad-y-retroalimentacion><a class=toclink href=../../2025/05/23/de-rag-b%C3%A1sico-a-avanzado/#nivel-4-evaluacion-de-calidad-y-retroalimentacion>Nivel 4: Evaluación de calidad y retroalimentación</a></h3> <p>Con la observabilidad establecida, el siguiente paso es implementar mecanismos sistemáticos para evaluar la calidad de las respuestas y crear ciclos de mejora continua. El Nivel 4 transforma el RAG de un sistema estático a uno que aprende y mejora con el tiempo.</p> <h4 id=estrategias-de-evaluacion-multidimensional><a class=toclink href=../../2025/05/23/de-rag-b%C3%A1sico-a-avanzado/#estrategias-de-evaluacion-multidimensional>Estrategias de evaluación multidimensional</a></h4> <p>En este nivel implementamos:</p> <ul> <li> <p><strong>Feedback directo de usuarios</strong>: Incorporamos mecanismos simples pero efectivos como botones de "útil/no útil" o escalas de satisfacción tras cada respuesta. Este feedback se correlaciona con los datos de observabilidad para identificar patrones.</p> </li> <li> <p><strong>Conjuntos de evaluación estáticos</strong>: Creamos un dataset de preguntas esperadas con respuestas ideales validadas por expertos. Periódicamente ejecutamos estas "pruebas de regresión" para verificar que el sistema mantiene o mejora su calidad.</p> </li> <li> <p><strong>Evaluación automatizada con LLMs</strong>: Utilizamos modelos como GPT-4 o Claude como "jueces" para evaluar la calidad de las respuestas. Por ejemplo, proporcionamos al juez la pregunta, la respuesta generada y las fuentes originales, pidiéndole que califique precisión, exhaustividad y relevancia.</p> </li> <li> <p><strong>Métricas proxy cuantitativas</strong>: Definimos indicadores indirectos de calidad como "tasa de respuestas con fuente" (porcentaje de respuestas que citan al menos un documento) o "tasa de fallback" (frecuencia con que el sistema responde "no tengo suficiente información").</p> </li> </ul> <h4 id=herramientas-de-evaluacion><a class=toclink href=../../2025/05/23/de-rag-b%C3%A1sico-a-avanzado/#herramientas-de-evaluacion>Herramientas de evaluación</a></h4> <p>El ecosistema ha evolucionado con soluciones especializadas:</p> <ul> <li> <p><strong>Frameworks de experimentación</strong>: Plataformas como LangSmith o DeepEval permiten crear datasets de evaluación y comparar sistemáticamente distintas versiones del sistema.</p> </li> <li> <p><strong>Plataformas de anotación</strong>: Herramientas que facilitan la revisión humana de muestras de respuestas, generando datos de entrenamiento para futuros modelos evaluadores.</p> </li> <li> <p><strong>Dashboards de calidad</strong>: Interfaces que muestran tendencias en métricas de calidad, permitiendo detectar degradaciones o mejoras tras cambios en el sistema.</p> </li> </ul> <h4 id=el-ciclo-de-mejora-continua-data-flywheel><a class=toclink href=../../2025/05/23/de-rag-b%C3%A1sico-a-avanzado/#el-ciclo-de-mejora-continua-data-flywheel>El ciclo de mejora continua (Data Flywheel)</a></h4> <p>La verdadera potencia del Nivel 4 está en cerrar el ciclo:</p> <ol> <li><strong>Instrumentación</strong>: Capturamos datos detallados de cada interacción</li> <li><strong>Análisis</strong>: Identificamos patrones y problemas recurrentes</li> <li><strong>Priorización</strong>: Seleccionamos las áreas de mayor impacto para mejorar</li> <li><strong>Implementación</strong>: Aplicamos correcciones (más datos, mejores prompts, etc.)</li> <li><strong>Medición</strong>: Verificamos el impacto de los cambios</li> <li><strong>Repetición</strong>: Continuamos el ciclo indefinidamente</li> </ol> <p>Este "volante de datos" genera un efecto compuesto donde cada mejora incrementa la calidad global del sistema, creando una ventaja competitiva sostenible.</p> <h4 id=impacto-estrategico-para-la-direccion-ejecutiva><a class=toclink href=../../2025/05/23/de-rag-b%C3%A1sico-a-avanzado/#impacto-estrategico-para-la-direccion-ejecutiva>Impacto estratégico para la dirección ejecutiva</a></h4> <p>El Nivel 4 representa un cambio fundamental:</p> <ul> <li><strong>Mejora predecible</strong>: La calidad del sistema ya no depende de intuiciones sino de un proceso sistemático medible.</li> <li><strong>Priorización informada</strong>: Las decisiones sobre qué mejorar se basan en datos concretos de uso e impacto.</li> <li><strong>Demostración de progreso</strong>: Se puede mostrar claramente cómo el sistema mejora con el tiempo, justificando la inversión continua.</li> </ul> <p>Sin embargo, aunque podemos medir y mejorar, todavía no tenemos un entendimiento profundo de las limitaciones fundamentales del sistema. Esto nos lleva al siguiente nivel de madurez.</p> <h3 id=nivel-5-analisis-de-limitaciones-y-puntos-debiles><a class=toclink href=../../2025/05/23/de-rag-b%C3%A1sico-a-avanzado/#nivel-5-analisis-de-limitaciones-y-puntos-debiles>Nivel 5: Análisis de limitaciones y puntos débiles</a></h3> <p>En el Nivel 5, aprovechamos toda la información recopilada en los niveles anteriores para realizar un diagnóstico sistemático de las limitaciones del sistema. Este nivel representa un salto cualitativo: pasamos de simplemente medir el rendimiento a entender profundamente por qué el sistema falla en ciertos casos.</p> <h4 id=analisis-sistematico-de-patrones-de-fallo><a class=toclink href=../../2025/05/23/de-rag-b%C3%A1sico-a-avanzado/#analisis-sistematico-de-patrones-de-fallo>Análisis sistemático de patrones de fallo</a></h4> <p>En este nivel implementamos:</p> <ul> <li> <p><strong>Clustering de consultas problemáticas</strong>: Agrupamos preguntas similares donde el sistema tuvo bajo rendimiento para identificar patrones. Por ejemplo, podríamos descubrir que las preguntas sobre "proyecciones financieras" consistentemente reciben respuestas de baja calidad.</p> </li> <li> <p><strong>Detección de alucinaciones recurrentes</strong>: Analizamos respuestas para identificar afirmaciones incorrectas repetitivas. Si el modelo inventa cifras específicas en lugar de admitir desconocimiento, es una señal de un problema estructural en los prompts o en la base de conocimiento.</p> </li> <li> <p><strong>Análisis de cobertura del conocimiento</strong>: Comparamos las preguntas de usuarios con los temas cubiertos en nuestra base para identificar brechas sistemáticas. Este mapa de calor revela áreas donde necesitamos incorporar nueva documentación.</p> </li> <li> <p><strong>Identificación de casos extremos</strong>: Detectamos consultas que generan comportamientos anómalos, como tiempos de respuesta excesivos o consumo desproporcionado de recursos, para implementar salvaguardas.</p> </li> </ul> <h4 id=diagnostico-modular-del-pipeline-rag><a class=toclink href=../../2025/05/23/de-rag-b%C3%A1sico-a-avanzado/#diagnostico-modular-del-pipeline-rag>Diagnóstico modular del pipeline RAG</a></h4> <p>Una práctica avanzada es analizar cada componente del sistema por separado:</p> <ul> <li><strong>Problemas de Retrieval</strong>: ¿La búsqueda falla en encontrar documentos relevantes aunque existan?</li> <li><strong>Problemas de Generation</strong>: ¿El modelo recibe información correcta pero responde mal?</li> <li><strong>Problemas de Orchestration</strong>: ¿El sistema necesita realizar pasos adicionales que no está ejecutando?</li> </ul> <p>Este enfoque modular permite dirigir recursos exactamente donde se necesitan, en lugar de reemplazar todo el sistema cuando solo un componente está fallando.</p> <h4 id=impacto-estrategico-para-decisiones-ejecutivas><a class=toclink href=../../2025/05/23/de-rag-b%C3%A1sico-a-avanzado/#impacto-estrategico-para-decisiones-ejecutivas>Impacto estratégico para decisiones ejecutivas</a></h4> <p>El Nivel 5 proporciona:</p> <ul> <li><strong>Mapa de ruta claro</strong>: Priorización basada en evidencia de qué componentes mejorar primero.</li> <li><strong>Gestión de expectativas</strong>: Capacidad para comunicar claramente qué puede y no puede hacer el sistema.</li> <li><strong>Decisiones de inversión informadas</strong>: Justificación para adquirir datos adicionales, mejorar modelos o implementar nuevas capacidades.</li> </ul> <h4 id=caso-de-estudio-analisis-multimodal-con-embed-4><a class=toclink href=../../2025/05/23/de-rag-b%C3%A1sico-a-avanzado/#caso-de-estudio-analisis-multimodal-con-embed-4>Caso de estudio: Análisis multimodal con Embed 4</a></h4> <p>En 2025, las limitaciones de los sistemas RAG tradicionales incluyen su capacidad para manejar contenido multimodal. Un análisis de Nivel 5 podría revelar que las consultas relacionadas con gráficos o tablas en documentos PDF tienen un rendimiento significativamente peor.</p> <p>La solución podría ser implementar modelos avanzados como Cohere Embed 4 (lanzado en abril 2025), que ofrece:</p> <ul> <li>Capacidad multimodal nativa para entender documentos complejos (PDFs, presentaciones) con texto, imágenes y tablas en un vector unificado</li> <li>Procesamiento de documentos extensos (hasta 128K tokens, aproximadamente 200 páginas)</li> <li>Soporte multilingüe para más de 100 idiomas</li> <li>Optimizaciones específicas para industrias reguladas como finanzas y salud</li> </ul> <p>Este tipo de actualización estratégica, basada en un análisis sistemático de limitaciones, puede transformar drásticamente la utilidad del sistema para casos de uso empresariales complejos.</p> <p>Al completar el Nivel 5, tenemos una comprensión profunda de dónde y por qué nuestro sistema RAG falla. Esto nos prepara para implementar mejoras avanzadas en los siguientes niveles, comenzando con la integración de fuentes de datos empresariales.</p> <h3 id=nivel-6-manejo-avanzado-de-datos-y-fuentes-empresariales><a class=toclink href=../../2025/05/23/de-rag-b%C3%A1sico-a-avanzado/#nivel-6-manejo-avanzado-de-datos-y-fuentes-empresariales>Nivel 6: Manejo avanzado de datos y fuentes empresariales</a></h3> <p>Hasta ahora nos hemos centrado principalmente en documentos textuales. Sin embargo, en entornos empresariales reales, la información crítica suele estar distribuida en múltiples sistemas: bases de datos relacionales, CRMs, ERPs, data warehouses y flujos de datos en tiempo real. El Nivel 6 integra estas fuentes estructuradas y semi-estructuradas al ecosistema RAG.</p> <h4 id=integracion-con-datos-estructurados><a class=toclink href=../../2025/05/23/de-rag-b%C3%A1sico-a-avanzado/#integracion-con-datos-estructurados>Integración con datos estructurados</a></h4> <p>En este nivel implementamos:</p> <ul> <li> <p><strong>Conexión con bases de datos empresariales</strong>: Habilitamos consultas en lenguaje natural que se traducen automáticamente a SQL, GraphQL o APIs específicas. Por ejemplo, si un usuario pregunta "¿Cuáles fueron las ventas del Q1 2025?", el sistema puede generar y ejecutar una consulta SQL a la base de datos financiera.</p> </li> <li> <p><strong>Acceso contextual a CRMs y ERPs</strong>: Integramos con sistemas como Salesforce, SAP o Microsoft Dynamics para recuperar información actualizada sobre clientes, proyectos o inventarios. Esto permite responder preguntas como "¿Cuál es el estado del proyecto Alfa?" con datos en tiempo real.</p> </li> <li> <p><strong>Interfaces con data warehouses</strong>: Conectamos con plataformas como Snowflake, Redshift o BigQuery para análisis de grandes volúmenes de datos históricos, permitiendo respuestas basadas en tendencias y agregaciones complejas.</p> </li> </ul> <h4 id=manejo-de-datos-multimodales><a class=toclink href=../../2025/05/23/de-rag-b%C3%A1sico-a-avanzado/#manejo-de-datos-multimodales>Manejo de datos multimodales</a></h4> <p>La información empresarial no es solo texto:</p> <ul> <li> <p><strong>Procesamiento de imágenes y diagramas</strong>: Implementamos capacidades para entender y referir contenido visual como gráficos, diagramas técnicos o imágenes de productos. </p> </li> <li> <p><strong>Extracción de tablas y datos estructurados</strong>: Utilizamos herramientas especializadas para interpretar tablas en documentos PDF, hojas de cálculo y presentaciones, convirtiendo datos tabulares en información procesable.</p> </li> <li> <p><strong>Unificación de representaciones vectoriales</strong>: Empleamos modelos avanzados de embeddings que pueden representar contenido mixto (texto + imágenes) en un espacio vectorial unificado, mejorando la búsqueda semántica en documentos complejos.</p> </li> </ul> <h4 id=actualizaciones-continuas-y-gestion-de-datos><a class=toclink href=../../2025/05/23/de-rag-b%C3%A1sico-a-avanzado/#actualizaciones-continuas-y-gestion-de-datos>Actualizaciones continuas y gestión de datos</a></h4> <p>Un sistema RAG maduro requiere:</p> <ul> <li> <p><strong>Pipelines de ingestión automatizados</strong>: Implementamos flujos que detectan cambios en las fuentes de datos y actualizan la base de conocimiento automáticamente. Por ejemplo, cuando se publica una nueva política interna, el sistema la indexa sin intervención manual.</p> </li> <li> <p><strong>Gestión de versiones de datos</strong>: Mantenemos registros de cuándo se indexó cada pieza de información, permitiendo consultas temporales como "¿Cuál era la política de precios en enero 2025?".</p> </li> <li> <p><strong>Arquitectura de datos desacoplada</strong>: Separamos los subsistemas de ingestión, almacenamiento y consulta, permitiendo que cada uno escale independientemente según las necesidades.</p> </li> </ul> <h4 id=seguridad-y-control-de-acceso-granular><a class=toclink href=../../2025/05/23/de-rag-b%C3%A1sico-a-avanzado/#seguridad-y-control-de-acceso-granular>Seguridad y control de acceso granular</a></h4> <p>En entornos empresariales, la seguridad es crítica:</p> <ul> <li> <p><strong>Filtrado por permisos de usuario</strong>: Aseguramos que los resultados de búsqueda respeten los permisos del usuario que realiza la consulta. Si un documento es confidencial y el usuario no tiene acceso, no aparecerá en los resultados.</p> </li> <li> <p><strong>Auditoría de acceso a datos</strong>: Registramos qué información se recupera y para quién, cumpliendo con requisitos regulatorios y de cumplimiento.</p> </li> <li> <p><strong>Manejo de información sensible</strong>: Implementamos capacidades para reconocer y proteger datos personales (PII), información financiera sensible o secretos comerciales.</p> </li> </ul> <h4 id=tecnologias-relevantes-en-2025><a class=toclink href=../../2025/05/23/de-rag-b%C3%A1sico-a-avanzado/#tecnologias-relevantes-en-2025>Tecnologías relevantes en 2025</a></h4> <p>El ecosistema de herramientas ha evolucionado para facilitar estas integraciones:</p> <ul> <li> <p><strong>Plataformas RAG integradas</strong>: Servicios como AWS Bedrock Knowledge Bases, Azure AI Search o Google Vertex AI Search permiten conectar múltiples fuentes de datos con capacidades de búsqueda semántica unificadas.</p> </li> <li> <p><strong>Modelos multimodales de embeddings</strong>: Soluciones como OpenAI CLIP, Cohere Embed 4 o modelos especializados de HuggingFace que unifican representaciones de texto e imágenes.</p> </li> <li> <p><strong>Herramientas de orquestación de datos</strong>: Frameworks como Dagster, Airflow o Prefect para gestionar flujos complejos de actualización de datos.</p> </li> </ul> <h4 id=impacto-empresarial-del-nivel-6><a class=toclink href=../../2025/05/23/de-rag-b%C3%A1sico-a-avanzado/#impacto-empresarial-del-nivel-6>Impacto empresarial del Nivel 6</a></h4> <p>El Nivel 6 representa un cambio fundamental en la utilidad del sistema:</p> <ul> <li><strong>Información siempre actualizada</strong>: Las respuestas reflejan el estado actual de la organización, no solo documentos estáticos.</li> <li><strong>Cobertura completa</strong>: El sistema puede responder preguntas que requieren datos de múltiples sistemas, eliminando silos de información.</li> <li><strong>Valor estratégico</strong>: El RAG se convierte en un punto central de acceso al conocimiento organizacional, aumentando la productividad y la toma de decisiones informadas.</li> </ul> <p>Con la integración de fuentes de datos empresariales, nuestro sistema RAG se vuelve significativamente más valioso. Sin embargo, todavía podemos mejorar cómo maneja consultas complejas, lo que nos lleva al siguiente nivel.</p> <h3 id=nivel-7-mejora-y-enriquecimiento-de-consultas><a class=toclink href=../../2025/05/23/de-rag-b%C3%A1sico-a-avanzado/#nivel-7-mejora-y-enriquecimiento-de-consultas>Nivel 7: Mejora y enriquecimiento de consultas</a></h3> <p>El Nivel 7 se enfoca en sofisticar la fase de consulta, transformando preguntas simples o ambiguas en búsquedas inteligentes que capturan mejor la intención del usuario. Este nivel marca la diferencia entre un sistema que solo responde a lo que se le pregunta literalmente y uno que entiende el contexto y las necesidades subyacentes.</p> <h4 id=manejo-avanzado-del-contexto-conversacional><a class=toclink href=../../2025/05/23/de-rag-b%C3%A1sico-a-avanzado/#manejo-avanzado-del-contexto-conversacional>Manejo avanzado del contexto conversacional</a></h4> <p>En entornos de diálogo, implementamos:</p> <ul> <li> <p><strong>Memoria de conversación estructurada</strong>: Mantenemos un historial contextual que permite entender referencias a conversaciones previas. Por ejemplo, si tras discutir políticas de vacaciones el usuario pregunta "¿Y para empleados con 5 años?", el sistema comprende que se refiere a "vacaciones para empleados con 5 años de antigüedad".</p> </li> <li> <p><strong>Resolución de referencias y anáforas</strong>: Implementamos modelos que resuelven expresiones como "ese proyecto", "ella" o "ese documento" basándose en el contexto previo, evitando que el usuario tenga que repetir información.</p> </li> <li> <p><strong>Detección de cambios de tema</strong>: Identificamos cuando una nueva pregunta inicia un tema diferente, reseteando apropiadamente el contexto para evitar confusiones.</p> </li> </ul> <h4 id=descomposicion-de-consultas-complejas><a class=toclink href=../../2025/05/23/de-rag-b%C3%A1sico-a-avanzado/#descomposicion-de-consultas-complejas>Descomposición de consultas complejas</a></h4> <p>Las preguntas empresariales suelen ser multifacéticas:</p> <ul> <li> <p><strong>Análisis de sub-preguntas</strong>: Dividimos consultas complejas en componentes más simples. Por ejemplo, "Compara nuestros resultados Q1 2025 con los competidores y explica las diferencias" se descompone en: (1) obtener resultados propios, (2) obtener resultados de competidores, (3) analizar diferencias.</p> </li> <li> <p><strong>Planificación de pasos de búsqueda</strong>: Utilizamos LLMs como planificadores que determinan qué información se necesita y en qué orden para responder completamente. Esto crea un árbol de decisiones que guía múltiples búsquedas secuenciales.</p> </li> <li> <p><strong>Ejecución de consultas en paralelo</strong>: Para preguntas que requieren información de distintas fuentes, ejecutamos búsquedas simultáneas y luego combinamos los resultados de forma coherente.</p> </li> </ul> <h4 id=tecnicas-avanzadas-de-enriquecimiento-de-consultas><a class=toclink href=../../2025/05/23/de-rag-b%C3%A1sico-a-avanzado/#tecnicas-avanzadas-de-enriquecimiento-de-consultas>Técnicas avanzadas de enriquecimiento de consultas</a></h4> <p>Mejoramos la precisión de la búsqueda con:</p> <ul> <li> <p><strong>Expansión semántica con conocimiento de dominio</strong>: Utilizamos ontologías y knowledge graphs específicos de la empresa para enriquecer consultas. Por ejemplo, si alguien pregunta por "NDA", expandimos a "Non-Disclosure Agreement" y términos relacionados como "confidencialidad" o "acuerdo de secreto".</p> </li> <li> <p><strong>Personalización por perfil de usuario</strong>: Adaptamos la búsqueda según el rol, departamento o historial del usuario. Un ejecutivo de finanzas y un ingeniero que preguntan lo mismo pueden recibir resultados optimizados para sus perspectivas.</p> </li> <li> <p><strong>Generación de variantes de consulta</strong>: Creamos múltiples reformulaciones de la misma pregunta para ampliar la cobertura. Por ejemplo, "política de viajes" podría generar variantes como "normativa de desplazamientos", "reembolso de gastos de viaje", etc.</p> </li> </ul> <h4 id=busqueda-iterativa-y-refinamiento><a class=toclink href=../../2025/05/23/de-rag-b%C3%A1sico-a-avanzado/#busqueda-iterativa-y-refinamiento>Búsqueda iterativa y refinamiento</a></h4> <p>Implementamos estrategias de auto-mejora:</p> <ul> <li> <p><strong>Feedback interno de relevancia</strong>: Si la primera búsqueda no produce resultados satisfactorios (baja similitud), el sistema reformula automáticamente la consulta y busca nuevamente.</p> </li> <li> <p><strong>Búsqueda con profundización progresiva</strong>: Comenzamos con consultas amplias y, basándonos en resultados iniciales, refinamos para obtener información más específica en pasos sucesivos.</p> </li> <li> <p><strong>Clarificación condicional</strong>: En casos de ambigüedad, el sistema puede solicitar aclaraciones al usuario antes de proceder, mejorando la precisión sin frustrar con preguntas innecesarias.</p> </li> </ul> <h4 id=arquitecturas-de-agentes-para-consultas><a class=toclink href=../../2025/05/23/de-rag-b%C3%A1sico-a-avanzado/#arquitecturas-de-agentes-para-consultas>Arquitecturas de agentes para consultas</a></h4> <p>En 2025, las implementaciones más avanzadas utilizan:</p> <ul> <li> <p><strong>Agentes especializados</strong>: Diferentes componentes manejan tipos específicos de consultas. Por ejemplo, un agente para preguntas financieras, otro para recursos humanos, etc., cada uno con conocimiento específico de dominio.</p> </li> <li> <p><strong>Orquestadores de consulta</strong>: Un componente central que decide qué agente debe manejar cada pregunta o cómo descomponerla entre varios agentes.</p> </li> <li> <p><strong>Frameworks de agentes</strong>: Plataformas como LangChain, AutoGPT o frameworks propietarios que facilitan la implementación de estos sistemas multi-agente con capacidades de razonamiento.</p> </li> </ul> <h4 id=impacto-empresarial-del-nivel-7><a class=toclink href=../../2025/05/23/de-rag-b%C3%A1sico-a-avanzado/#impacto-empresarial-del-nivel-7>Impacto empresarial del Nivel 7</a></h4> <p>El Nivel 7 representa:</p> <ul> <li><strong>Mayor tasa de resolución</strong>: El sistema responde correctamente a preguntas que antes fallaba por ser demasiado literales o limitadas.</li> <li><strong>Experiencia conversacional natural</strong>: Los usuarios pueden dialogar con el sistema como lo harían con un experto humano, sin necesidad de formular preguntas perfectas.</li> <li><strong>Capacidad para manejar consultas estratégicas</strong>: El sistema puede abordar preguntas complejas que requieren sintetizar información de múltiples fuentes y perspectivas.</li> </ul> <p>Con estas capacidades avanzadas de consulta, nuestro sistema RAG puede manejar interacciones mucho más sofisticadas. Sin embargo, cuando recuperamos grandes volúmenes de información relevante, necesitamos mecanismos para sintetizarla efectivamente, lo que nos lleva al siguiente nivel.</p> <h3 id=nivel-8-tecnicas-de-resumen-y-sintesis-de-informacion><a class=toclink href=../../2025/05/23/de-rag-b%C3%A1sico-a-avanzado/#nivel-8-tecnicas-de-resumen-y-sintesis-de-informacion>Nivel 8: Técnicas de resumen y síntesis de información</a></h3> <p>A medida que los sistemas RAG se vuelven más potentes en la recuperación de información, surge un nuevo desafío: la sobrecarga de datos. Cuando una consulta devuelve decenas de fragmentos relevantes, presentarlos todos al usuario resulta abrumador. El Nivel 8 se enfoca en condensar y sintetizar grandes volúmenes de información en respuestas concisas y estructuradas.</p> <h4 id=estrategias-de-sumarizacion-para-grandes-volumenes-de-datos><a class=toclink href=../../2025/05/23/de-rag-b%C3%A1sico-a-avanzado/#estrategias-de-sumarizacion-para-grandes-volumenes-de-datos>Estrategias de sumarización para grandes volúmenes de datos</a></h4> <p>En este nivel implementamos:</p> <ul> <li> <p><strong>Patrón map-reduce para documentos múltiples</strong>: Primero resumimos cada documento o fragmento individualmente (map), luego combinamos estos resúmenes en una respuesta cohesiva (reduce). Esta técnica permite procesar eficientemente grandes cantidades de información sin exceder los límites de contexto de los LLMs.</p> </li> <li> <p><strong>Sumarización jerárquica</strong>: Aplicamos resúmenes a diferentes niveles de granularidad. Por ejemplo, primero resumimos párrafos, luego secciones, luego documentos completos, manteniendo la estructura jerárquica de la información.</p> </li> <li> <p><strong>Extracción de puntos clave</strong>: En lugar de resumir todo el texto, identificamos y extraemos solo los datos más relevantes para la consulta específica, eliminando información tangencial.</p> </li> </ul> <h4 id=respuestas-estructuradas-por-niveles-de-detalle><a class=toclink href=../../2025/05/23/de-rag-b%C3%A1sico-a-avanzado/#respuestas-estructuradas-por-niveles-de-detalle>Respuestas estructuradas por niveles de detalle</a></h4> <p>Mejoramos la experiencia del usuario con:</p> <ul> <li> <p><strong>Respuestas en capas</strong>: Proporcionamos primero un resumen ejecutivo conciso (1-2 párrafos), seguido de detalles adicionales organizados por relevancia. El usuario puede profundizar según su interés.</p> </li> <li> <p><strong>Segmentación por aspectos</strong>: Para preguntas multifacéticas, estructuramos la respuesta por aspectos o dimensiones. Por ejemplo, ante "Explica nuestra estrategia de expansión internacional", podríamos separar la respuesta en "Mercados objetivo", "Cronograma", "Inversión requerida" y "Riesgos identificados".</p> </li> <li> <p><strong>Formatos adaptados al contenido</strong>: Utilizamos automáticamente el formato más adecuado según el tipo de información: listas para enumeraciones, tablas para datos comparativos, gráficos para tendencias, etc.</p> </li> </ul> <h4 id=aprovechamiento-de-modelos-de-contexto-extendido><a class=toclink href=../../2025/05/23/de-rag-b%C3%A1sico-a-avanzado/#aprovechamiento-de-modelos-de-contexto-extendido>Aprovechamiento de modelos de contexto extendido</a></h4> <p>En 2025, los avances en LLMs permiten:</p> <ul> <li> <p><strong>Procesamiento de documentos extensos completos</strong>: Utilizamos modelos con ventanas de contexto amplias para procesar documentos enteros sin fragmentación, mejorando la coherencia de las respuestas.</p> </li> <li> <p><strong>Compresión semántica de contexto</strong>: Implementamos técnicas que comprimen información manteniendo el significado, permitiendo incluir más contenido relevante dentro de los límites del modelo.</p> </li> <li> <p><strong>Análisis selectivo de profundidad variable</strong>: Procesamos partes críticas del documento con mayor detalle mientras resumimos secciones menos relevantes, optimizando el uso del contexto disponible.</p> </li> </ul> <h4 id=tecnicas-avanzadas-de-sintesis><a class=toclink href=../../2025/05/23/de-rag-b%C3%A1sico-a-avanzado/#tecnicas-avanzadas-de-sintesis>Técnicas avanzadas de síntesis</a></h4> <p>Para respuestas de mayor calidad:</p> <ul> <li> <p><strong>Reconciliación de información contradictoria</strong>: Cuando diferentes fuentes presentan datos inconsistentes, el sistema identifica y señala estas discrepancias, proporcionando contexto sobre cada fuente.</p> </li> <li> <p><strong>Síntesis temporal</strong>: Para preguntas que abarcan diferentes períodos ("¿Cómo ha evolucionado nuestra política de teletrabajo desde 2020?"), sintetizamos información cronológicamente, destacando cambios significativos.</p> </li> <li> <p><strong>Análisis comparativo automático</strong>: Generamos comparaciones estructuradas entre entidades, productos o períodos, incluso cuando esta comparación no está explícita en los documentos originales.</p> </li> </ul> <h4 id=herramientas-y-modelos-especializados-en-2025><a class=toclink href=../../2025/05/23/de-rag-b%C3%A1sico-a-avanzado/#herramientas-y-modelos-especializados-en-2025>Herramientas y modelos especializados en 2025</a></h4> <p>El ecosistema ha evolucionado con soluciones específicas:</p> <ul> <li> <p><strong>Modelos especializados en sumarización</strong>: Además de LLMs generales, existen modelos optimizados específicamente para tareas de resumen que ofrecen mejor rendimiento con menor costo.</p> </li> <li> <p><strong>Frameworks de sumarización multi-documento</strong>: Bibliotecas y servicios que implementan patrones map-reduce y otras técnicas de síntesis a escala.</p> </li> <li> <p><strong>Herramientas de visualización dinámica</strong>: Componentes que transforman automáticamente datos extraídos en visualizaciones significativas como parte de la respuesta.</p> </li> </ul> <h4 id=impacto-empresarial-del-nivel-8><a class=toclink href=../../2025/05/23/de-rag-b%C3%A1sico-a-avanzado/#impacto-empresarial-del-nivel-8>Impacto empresarial del Nivel 8</a></h4> <p>El Nivel 8 representa:</p> <ul> <li> <p><strong>Eficiencia cognitiva</strong>: Los usuarios obtienen la información esencial sin tener que procesar grandes volúmenes de texto, acelerando la toma de decisiones.</p> </li> <li> <p><strong>Democratización del conocimiento</strong>: Información compleja se vuelve accesible para usuarios no especializados gracias a síntesis bien estructuradas.</p> </li> <li> <p><strong>Escalabilidad del conocimiento</strong>: El sistema puede manejar bases de conocimiento empresariales masivas sin degradar la calidad de las respuestas.</p> </li> </ul> <p>Con estas capacidades de síntesis, nuestro sistema RAG no solo recupera información relevante sino que la presenta de forma óptima para el consumo humano. Sin embargo, para maximizar el valor empresarial, necesitamos alinear todo el sistema con métricas de negocio y establecer procesos de mejora continua, lo que nos lleva al nivel final de madurez.</p> <h3 id=nivel-9-modelado-de-resultados-y-mejora-continua-del-sistema><a class=toclink href=../../2025/05/23/de-rag-b%C3%A1sico-a-avanzado/#nivel-9-modelado-de-resultados-y-mejora-continua-del-sistema>Nivel 9: Modelado de resultados y mejora continua del sistema</a></h3> <p>El nivel final de madurez RAG trasciende los aspectos técnicos para enfocarse en el impacto empresarial y la optimización continua. En este nivel, alineamos el sistema con los objetivos estratégicos de la organización y establecemos procesos para que evolucione y mejore constantemente.</p> <h4 id=alineacion-con-metricas-de-negocio><a class=toclink href=../../2025/05/23/de-rag-b%C3%A1sico-a-avanzado/#alineacion-con-metricas-de-negocio>Alineación con métricas de negocio</a></h4> <p>En este nivel implementamos:</p> <ul> <li> <p><strong>KPIs específicos por caso de uso</strong>: Definimos indicadores concretos según el propósito del sistema. Para un asistente de soporte interno, podría ser "tasa de resolución sin escalamiento"; para un asistente de ventas, "conversión de consultas a oportunidades calificadas".</p> </li> <li> <p><strong>Análisis de impacto en productividad</strong>: Medimos sistemáticamente el tiempo ahorrado, la reducción de errores o la aceleración de procesos atribuibles al sistema RAG, traduciendo estos beneficios a valor monetario.</p> </li> <li> <p><strong>Evaluación de satisfacción contextualizada</strong>: Vamos más allá del simple "¿fue útil?" para entender el impacto en diferentes segmentos de usuarios, departamentos o tipos de consultas.</p> </li> </ul> <h4 id=ciclos-de-aprendizaje-y-mejora-continua><a class=toclink href=../../2025/05/23/de-rag-b%C3%A1sico-a-avanzado/#ciclos-de-aprendizaje-y-mejora-continua>Ciclos de aprendizaje y mejora continua</a></h4> <p>Establecemos procesos sostenibles:</p> <ul> <li> <p><strong>Fine-tuning iterativo de modelos</strong>: Utilizamos los datos acumulados de interacciones para afinar periódicamente los modelos de embeddings o incluso los LLMs, adaptándolos mejor al lenguaje y contexto específicos de la organización.</p> </li> <li> <p><strong>Actualización priorizada de conocimiento</strong>: Basándonos en análisis de brechas y consultas frecuentes, priorizamos qué nuevas fuentes de datos incorporar o qué documentación actualizar.</p> </li> <li> <p><strong>Evolución de prompts y plantillas</strong>: Refinamos continuamente las instrucciones al modelo basándonos en análisis de casos exitosos y fallidos, mejorando la consistencia y calidad de las respuestas.</p> </li> </ul> <h4 id=despliegues-graduales-y-experimentacion-controlada><a class=toclink href=../../2025/05/23/de-rag-b%C3%A1sico-a-avanzado/#despliegues-graduales-y-experimentacion-controlada>Despliegues graduales y experimentación controlada</a></h4> <p>Aplicamos prácticas de MLOps:</p> <ul> <li> <p><strong>A/B testing sistemático</strong>: Comparamos diferentes configuraciones del sistema (modelos, prompts, estrategias de búsqueda) con subconjuntos de usuarios para medir su impacto antes de implementarlos globalmente.</p> </li> <li> <p><strong>Canary deployments</strong>: Implementamos cambios significativos primero a un pequeño porcentaje de usuarios, monitorizando métricas clave antes de expandir gradualmente.</p> </li> <li> <p><strong>Entornos de staging con datos sintéticos</strong>: Probamos cambios en entornos controlados con datos representativos pero seguros, evaluando rendimiento y seguridad antes de llegar a producción.</p> </li> </ul> <h4 id=optimizacion-costo-beneficio><a class=toclink href=../../2025/05/23/de-rag-b%C3%A1sico-a-avanzado/#optimizacion-costo-beneficio>Optimización costo-beneficio</a></h4> <p>Balanceamos recursos y resultados:</p> <ul> <li> <p><strong>Estratificación de modelos por complejidad</strong>: Utilizamos modelos más ligeros y económicos para consultas simples, reservando los modelos premium para casos complejos que realmente los requieren.</p> </li> <li> <p><strong>Políticas de caché inteligente</strong>: Almacenamos respuestas a preguntas frecuentes o computacionalmente costosas, reduciendo llamadas a APIs y mejorando tiempos de respuesta.</p> </li> <li> <p><strong>Análisis de ROI por componente</strong>: Evaluamos qué elementos del sistema generan mayor valor en relación a su costo, dirigiendo recursos donde el impacto es más significativo.</p> </li> </ul> <h4 id=gobernanza-y-gestion-del-cambio><a class=toclink href=../../2025/05/23/de-rag-b%C3%A1sico-a-avanzado/#gobernanza-y-gestion-del-cambio>Gobernanza y gestión del cambio</a></h4> <p>Aseguramos la sostenibilidad organizacional:</p> <ul> <li> <p><strong>Equipos multidisciplinarios de supervisión</strong>: Establecemos grupos que incluyen especialistas técnicos, expertos en la materia y stakeholders de negocio para evaluar y dirigir la evolución del sistema.</p> </li> <li> <p><strong>Programas de capacitación continua</strong>: Educamos a los usuarios sobre cómo aprovechar al máximo el sistema, incluyendo cómo formular consultas efectivas y proporcionar feedback útil.</p> </li> <li> <p><strong>Documentación de decisiones y aprendizajes</strong>: Mantenemos un registro de cambios, experimentos y sus resultados, creando una base de conocimiento sobre el propio sistema RAG.</p> </li> </ul> <h4 id=impacto-estrategico-del-nivel-9><a class=toclink href=../../2025/05/23/de-rag-b%C3%A1sico-a-avanzado/#impacto-estrategico-del-nivel-9>Impacto estratégico del Nivel 9</a></h4> <p>El Nivel 9 representa:</p> <ul> <li> <p><strong>Ventaja competitiva sostenible</strong>: El sistema mejora continuamente, ampliando la brecha con competidores que utilizan implementaciones estáticas.</p> </li> <li> <p><strong>Capitalización del conocimiento</strong>: La organización construye un activo intelectual valioso que crece y se refina con cada interacción.</p> </li> <li> <p><strong>Adaptabilidad al cambio</strong>: El sistema evoluciona naturalmente con la organización, manteniendo su relevancia a pesar de cambios en el mercado o en las prioridades internas.</p> </li> </ul> <h3 id=el-camino-hacia-la-excelencia-en-sistemas-rag><a class=toclink href=../../2025/05/23/de-rag-b%C3%A1sico-a-avanzado/#el-camino-hacia-la-excelencia-en-sistemas-rag>El camino hacia la excelencia en sistemas RAG</a></h3> <p>A lo largo de este recorrido por los nueve niveles de madurez RAG, hemos visto cómo estas implementaciones pueden evolucionar desde simples prototipos hasta sofisticados sistemas empresariales que transforman organizaciones.</p> <h4 id=la-progresion-estrategica><a class=toclink href=../../2025/05/23/de-rag-b%C3%A1sico-a-avanzado/#la-progresion-estrategica>La progresión estratégica</a></h4> <p>El viaje desde el Nivel 0 (RAG mínimo viable) hasta el Nivel 9 (modelado de resultados) no es necesariamente lineal ni requiere completar cada nivel antes de avanzar al siguiente. Muchas organizaciones pueden implementar aspectos de niveles superiores mientras continúan desarrollando capacidades fundamentales.</p> <p>Lo importante es reconocer que RAG no es simplemente "conectar un LLM a una base de datos vectorial". Es un ecosistema complejo que puede y debe evolucionar con el tiempo, agregando capacidades como:</p> <ul> <li>Observabilidad y evaluación sistemática (Niveles 3-4)</li> <li>Integración con sistemas empresariales existentes (Nivel 6)</li> <li>Manejo inteligente de consultas complejas (Nivel 7)</li> <li>Síntesis avanzada de información (Nivel 8)</li> <li>Alineación con objetivos de negocio (Nivel 9)</li> </ul> <h4 id=recomendaciones-para-ctos-y-lideres-tecnicos><a class=toclink href=../../2025/05/23/de-rag-b%C3%A1sico-a-avanzado/#recomendaciones-para-ctos-y-lideres-tecnicos>Recomendaciones para CTOs y líderes técnicos</a></h4> <p>Si estás considerando implementar o mejorar un sistema RAG en tu organización:</p> <ol> <li> <p><strong>Comienza con un MVP enfocado</strong>: Identifica un caso de uso específico con alto valor potencial y comienza con una implementación básica (Niveles 0-2).</p> </li> <li> <p><strong>Instrumenta desde el principio</strong>: Incorpora observabilidad (Nivel 3) temprano para entender el comportamiento real del sistema y guiar mejoras.</p> </li> <li> <p><strong>Prioriza basándote en datos</strong>: Utiliza la información de uso y feedback para decidir qué niveles avanzados implementar primero según las necesidades específicas de tus usuarios.</p> </li> <li> <p><strong>Equilibra innovación y estabilidad</strong>: Implementa mejoras incrementales mediante experimentación controlada, manteniendo la confiabilidad del sistema.</p> </li> <li> <p><strong>Construye un equipo multidisciplinario</strong>: Los sistemas RAG exitosos requieren experiencia en ingeniería de datos, ML/IA, diseño de UX y conocimiento del dominio empresarial.</p> </li> </ol> <h4 id=el-futuro-de-rag-en-entornos-empresariales><a class=toclink href=../../2025/05/23/de-rag-b%C3%A1sico-a-avanzado/#el-futuro-de-rag-en-entornos-empresariales>El futuro de RAG en entornos empresariales</a></h4> <p>A mayo de 2025, los sistemas RAG han madurado significativamente, pero la evolución continúa. Las tendencias emergentes incluyen:</p> <ul> <li>Mayor integración con capacidades de razonamiento y planificación</li> <li>Sistemas multimodales que manejan nativamente texto, imágenes, audio y vídeo</li> <li>Personalización más profunda basada en el contexto y preferencias del usuario</li> <li>Capacidades de acción directa, no solo de recuperación de información</li> </ul> <p>Las organizaciones que establezcan hoy una base sólida en RAG estarán mejor posicionadas para adoptar estas capacidades avanzadas en el futuro.</p> <p>La implementación de sistemas RAG no es solo un proyecto tecnológico; es una iniciativa estratégica que puede transformar cómo las organizaciones acceden, utilizan y aprovechan su conocimiento colectivo. Los CTOs visionarios entienden que el verdadero valor no está en la tecnología por sí misma, sino en cómo esta tecnología potencia a las personas para tomar mejores decisiones, resolver problemas complejos y liberar su creatividad.</p> <p>Si estás comenzando tu viaje RAG o buscando llevar tu implementación actual al siguiente nivel, recuerda que cada organización tiene necesidades únicas. La clave está en aplicar estos principios de forma adaptativa, midiendo el impacto en cada paso y evolucionando continuamente hacia un sistema que genere valor tangible para tu organización.</p> <p><em>¿Estás implementando sistemas RAG en tu organización? ¿Tienes dudas sobre qué nivel de madurez es adecuado para tus necesidades específicas? Contáctame para una evaluación personalizada y una hoja de ruta estratégica adaptada a tus objetivos de negocio.</em></p> </div> </article> <article class="md-post md-post--excerpt"> <header class=md-post__header> <div class="md-post__meta md-meta"> <ul class=md-meta__list> <li class=md-meta__item> <time datetime="2025-01-31 00:00:00+00:00">2025/01/31</time></li> <li class=md-meta__item> 4 min read </li> </ul> </div> </header> <div class="md-post__content md-typeset"> <h2 id=la-trampa-del-conocimiento-instantaneo-lo-que-tu-cerebro-pierde-cuando-delegas-la-comprension-a-la-ia><a href=../../2025/01/31/lo-que-tu-cerebro-pierde-cuando-delegas-la-comprensi%C3%B3n-a-la-ia/ class=toclink>La Trampa del Conocimiento Instantáneo: Lo que tu cerebro pierde cuando delegas la comprensión a la IA</a></h2> <p><strong>Marcelo Acosta Cavalero</strong> </p> <hr> <p>En 2025, los ejecutivos de alto nivel están usando ChatGPT, NotebookLM, DeepSeek y otras IAs para "procesar" cantidades masivas de información: reportes trimestrales, papers de investigación, análisis de mercado. Videos de una hora se convierten en resúmenes de tres minutos, podcasts de dos horas en bullet points de 400 palabras. La promesa es tentadora: consumir en minutos lo que antes tomaba días.</p> <p>Pero la neurociencia nos alerta de algo inquietante: esta "eficiencia" podría estar creando una generación de líderes con conocimiento superficial y poca capacidad de análisis profundo. No es lo mismo escuchar una conversación profunda que leer sus puntos principales, ni ver el desarrollo completo de una idea que consumir su conclusión.</p> <p>El problema no es la tecnología en sí, sino cómo la estamos usando. Cuando delegamos la comprensión a una IA, nuestro cerebro pierde la oportunidad crucial de construir algo que ningún modelo de lenguaje puede replicar: entendimiento real.</p> <p>Cuando consumimos información, nuestro cerebro no funciona como un disco duro que simplemente almacena datos. Es más parecido a un escultor que, con cada lectura, cada reflexión, cada conexión que hacemos, va moldeando físicamente nuestras neuronas.</p> <p>Cada vez que prestamos atención real a una idea, que luchamos por entender un concepto complejo, nuestro cerebro activa circuitos neuronales específicos. Estas neuronas se recubren gradualmente de mielina, una sustancia que funciona como un aislante natural, haciendo que estos circuitos sean más eficientes y duraderos.</p> <p>Es como construir un camino en la selva: la primera vez que lo recorres, es difícil y lento. Pero cada vez que vuelves a pasar, el camino se hace más claro, más definido, más permanente.</p> <p>Los resúmenes de IA, por otro lado, son como sobrevolar la selva en helicóptero: llegas rápido a tu destino, pero no construyes ningún camino.</p> <p>Un CEO que entiende realmente su industria no memoriza datos: desarrolla una intuición profunda que surge de miles de horas de procesar información, conectar puntos, analizar fracasos y éxitos. Esta capacidad de ver patrones y anticipar movimientos del mercado no viene de resúmenes: viene de construir esos caminos neuronales, uno a uno, con tiempo y atención.</p> <p>Cuando delegamos la comprensión inicial a una IA, perdemos algo crucial: el proceso de lucha cognitiva que fortalece estos circuitos. Los estudios sobre mielinización muestran que nuestro cerebro necesita ese "esfuerzo productivo" para crear conexiones duraderas. No es el conocimiento en sí lo que importa, sino el proceso de adquirirlo.</p> <p>Es la diferencia entre memorizar las conclusiones de un reporte de mercado y entender verdaderamente por qué esas conclusiones tienen sentido. Entre saber que una estrategia funcionó y comprender profundamente los mecanismos que la hicieron funcionar.</p> <p>Los grandes errores estratégicos rara vez vienen de falta de información. En una era donde cualquier dato está a un prompt de distancia, los tropiezos corporativos nacen de otra fuente: la incapacidad de procesar esa información con profundidad.</p> <p>Tomemos el caso del comercio minorista y la transformación digital. Los ejecutivos que solo leyeron resúmenes sobre el impacto de Amazon se enfocaron en copiar lo obvio: crear tiendas online, ofrecer envíos rápidos. Los que estudiaron a fondo el fenómeno entendieron algo más valioso: Amazon no era una tienda digital, sino una empresa de datos que vendía productos.</p> <p>Esta diferencia de comprensión no es sutil: marcó la diferencia entre quienes sobrevivieron y quienes desaparecieron.</p> <p>Antes de una reunión de directorio, en lugar de pedir un resumen instantáneo de los últimos reportes financieros, dedica 30 minutos a los números clave y tendencias. Cuando tu cerebro lucha con los datos, está construyendo conexiones que te servirán para detectar anomalías o patrones en el futuro. Después, usa la IA para verificar si pasaste algo por alto.</p> <p>Para analizar la competencia, comienza viendo sus presentaciones completas, estudiando sus movimientos recientes. La IA puede ayudarte después a organizar la información y buscar patrones en grandes volúmenes de datos históricos, pero la intuición estratégica viene de tu análisis inicial.</p> <p>En el desarrollo de productos, ningún resumen puede reemplazar la experiencia de escuchar directamente el feedback de los usuarios. La IA puede ayudar a categorizar miles de comentarios, pero la comprensión profunda nace de la inmersión en las necesidades reales del cliente.</p> <p>En un mundo donde todos tienen acceso a las mismas herramientas de IA, la diferencia estará en quienes mantuvieron y desarrollaron su capacidad de pensamiento profundo. No es casualidad que líderes como Warren Buffett o Charlie Munger dedicaran varias horas diarias a leer y pensar.</p> <p>Los ejecutivos que dependen exclusivamente de resúmenes y análisis automatizados terminarán tomando las mismas decisiones obvias que sus competidores. La verdadera ventaja competitiva vendrá de la capacidad de ver lo que otros no ven, de conectar puntos que los algoritmos no pueden relacionar.</p> <p>El desafío no es procesar más información en menos tiempo, sino desarrollar la capacidad de extraer conocimiento significativo de ella. En la era de la IA, paradójicamente, el pensamiento profundo se vuelve más valioso, no menos.</p> <p>La próxima vez que tu instinto te diga "pide un resumen", pregúntate: ¿estoy construyendo una comprensión duradera o solo acumulando datos superficiales?</p> <p>La ironía de nuestra época es que, en nuestra búsqueda de eficiencia, estamos sacrificando la efectividad real. Cada vez que elegimos el resumen rápido sobre la comprensión profunda, cada podcast acelerado, cada video resumido, cada informe sintetizado por IA, estamos optando por una ilusión de conocimiento.</p> <p>Los grandes avances en los negocios, las innovaciones que cambian industrias, rara vez vienen de procesar más información más rápido. Vienen de esos momentos de claridad que solo surgen después de una inmersión profunda en el tema, de esas conexiones inesperadas que tu cerebro hace cuando le das tiempo para procesar, analizar y entender verdaderamente.</p> <p>La mielinización de nuestros circuitos neuronales no es opcional: es el proceso fundamental que nos permite desarrollar la intuición experta que diferencia a los grandes líderes. No hay atajos para esto.</p> <p>La próxima vez que tengas la tentación de pedir un resumen, recuerda: la verdadera productividad no se mide en tiempo ahorrado, sino en comprensión ganada.</p> </div> </article> <article class="md-post md-post--excerpt"> <header class=md-post__header> <div class="md-post__meta md-meta"> <ul class=md-meta__list> <li class=md-meta__item> <time datetime="2025-01-14 00:00:00+00:00">2025/01/14</time></li> <li class=md-meta__item> 2 min read </li> </ul> </div> </header> <div class="md-post__content md-typeset"> <h2 id=programadores-ia-la-realidad-detras-del-hype><a href=../../2025/01/14/la-realidad-detr%C3%A1s-del-hype-programadores-e-ia/ class=toclink>Programadores + IA: La realidad detrás del hype</a></h2> <p><strong>Marcelo Acosta Cavalero</strong> </p> <p>La Universidad de St. Pölten publicó en agosto de 2024 un estudio que mide el impacto real de ChatGPT en el desarrollo de software. Los datos muestran que los estudiantes que usaron ChatGPT produjeron código con menos errores y menor complejidad. </p> <p>Entonces, ¿podemos decirle al CFO que se quede tranquilo, que pronto reemplazaremos a todos los desarrolladores con IA? No tan rápido.</p> <p>El estudio comparó el código de dos grupos de estudiantes. El grupo que usó ChatGPT redujo a la mitad las violaciones de estándares de programación. La complejidad del código también bajó, con una diferencia estadística significativa (p &lt; 0.005). Las prácticas de diseño de software mejoraron en el grupo que usó ChatGPT.</p> <p>Pero estos resultados recuerdan a un caso médico de 1970. Un estudio en Yale mostró que las mujeres que tomaban estrógenos tenían más cáncer. La conclusión parecía clara: el estrógeno causaba cáncer. Sin embargo, un estudio en Boston reveló que el estrógeno solo hacía más visible algo que ya existía, causaba sangrados que llevaban a más exámenes médicos y más detección de casos existentes.</p> <p>Este paralelo nos ayuda a entender mejor los resultados del estudio. El código más limpio no necesariamente significa mejores programadores, igual que más detección de cáncer no significaba más casos nuevos. Las empresas que reportan mejores resultados con IA suelen ser las que ya tenían buenos procesos y equipos sólidos.</p> <p>Los CEO y CTO necesitan evaluar tres aspectos que el estudio no midió:</p> <p>La traducción de requisitos. Los ejercicios del estudio tenían especificaciones precisas. En proyectos reales, los desarrolladores pasan más tiempo entendiendo qué construir que escribiendo código.</p> <p>El mantenimiento de sistemas. Los estudiantes escribieron código nuevo para ejercicios individuales. Los desarrolladores profesionales heredan sistemas complejos, debuggean código existente y modifican arquitecturas que deben seguir funcionando.</p> <p>La colaboración. Los estudiantes trabajaron solos. Los equipos de desarrollo necesitan coordinar cambios, revisar código entre pares y mantener la consistencia técnica entre múltiples desarrolladores.</p> <p>Un desarrollador que solo sabe escribir código limpio con ayuda de IA es como un arquitecto que solo sabe usar AutoCAD; tiene las herramientas pero le falta lo esencial. Los mejores equipos de desarrollo no son los que escriben el código más limpio, sino los que resuelven los problemas correctos.</p> <p>Las empresas que hoy obtienen los mejores resultados con IA no están reemplazando desarrolladores, están cambiando cómo trabajan. Usan la IA para tareas mecánicas como escribir tests unitarios o refactorizar código, liberando tiempo para lo que realmente importa: entender problemas de negocio y diseñar soluciones.</p> <p>Para los directivos, el mensaje es claro: la IA no reemplazará a los programadores, pero sí cambiará qué hace valioso a un desarrollador. Las empresas que entiendan esto tendrán una ventaja significativa en los próximos años.</p> </div> </article> <article class="md-post md-post--excerpt"> <header class=md-post__header> <div class="md-post__meta md-meta"> <ul class=md-meta__list> <li class=md-meta__item> <time datetime="2025-01-09 00:00:00+00:00">2025/01/09</time></li> <li class=md-meta__item> 5 min read </li> </ul> </div> </header> <div class="md-post__content md-typeset"> <h2 id=escalamiento-responsable-de-ia-donde-termina-la-responsabilidad-del-proveedor-y-donde-empieza-la-tuya><a href=../../2025/01/09/escalamiento-responsable-de-ia-d%C3%B3nde-termina-la-responsabilidad-del-proveedor-y-d%C3%B3nde-empieza-la-tuya/ class=toclink>Escalamiento Responsable de IA: Dónde termina la responsabilidad del proveedor y dónde empieza la tuya</a></h2> <h3 id=marcelo-acosta-cavalero><a class=toclink href=../../2025/01/09/escalamiento-responsable-de-ia-d%C3%B3nde-termina-la-responsabilidad-del-proveedor-y-d%C3%B3nde-empieza-la-tuya/#marcelo-acosta-cavalero><strong>Marcelo Acosta Cavalero</strong></a></h3> <p>Cuando hablamos de Responsible Scaling Policy (RSP) en IA, muchas empresas entran en pánico pensando que necesitan implementar políticas complejas como las de Anthropic. Pero vamos a aclarar algo importante: hay una gran diferencia entre quien desarrolla modelos base de IA y quien los implementa en casos de uso específicos.</p> <p>Si tu empresa está usando modelos ya existentes (como Claude, GPT, etc.) para crear soluciones específicas (por ejemplo, un sistema RAG para soporte al cliente), no necesitas replicar toda la infraestructura de seguridad de Anthropic. Es como la diferencia entre fabricar un auto y usarlo: no necesitas entender cada detalle de seguridad del motor para conducir de manera responsable.</p> <p>Lo que sí necesitas entender es qué garantías te ofrece el proveedor de IA que elegiste. Cuando Anthropic implementa su RSP, está estableciendo límites claros sobre qué puede y no puede hacer su IA, y qué salvaguardas tiene implementadas. Esto te da un marco de seguridad base sobre el cual construir.</p> <p>Pero ojo, esto no significa que puedas despreocuparte completamente de la seguridad y responsabilidad. Tu empresa necesita enfocarse en aspectos específicos de tu implementación. La calidad y seguridad de los datos que alimentas al sistema es fundamental, así como el monitoreo constante de las respuestas que genera y los límites específicos de tu caso de uso.</p> <p>Pensemos en un sistema RAG para soporte técnico. Tu principal preocupación no debería ser si el modelo base puede ser usado para crear código malicioso; de eso ya se encargó el proveedor. En cambio, necesitas asegurarte de que tu implementación específica no exponga accidentalmente información confidencial de otros clientes cuando responde preguntas. También es crucial verificar que las respuestas se basen exclusivamente en tu documentación oficial y no en información potencialmente desactualizada o incorrecta que el modelo pueda tener de su entrenamiento general.</p> <p>Quizás el punto más crítico es establecer mecanismos claros para que el sistema reconozca cuándo debe escalar una consulta a un humano. No todos los problemas deberían ser manejados por IA, y parte de una implementación responsable es saber cuándo dar un paso atrás.</p> <p>La implementación de estos controles comienza mucho antes de poner el sistema en producción. El primer paso es crear un documento claro que defina los límites de tu sistema: qué tipos de consultas puede manejar, cuáles debe escalar inmediatamente, y qué información está completamente fuera de límites. Este no es un documento que quedará guardado en un cajón, debe ser una guía viva que evolucione con tu implementación.</p> <p>La seguridad de los datos requiere un enfoque práctico y realista. Por ejemplo, cuando procesas tu documentación para el sistema RAG, necesitas revisar meticulosamente qué información estás incluyendo. No es solo cuestión de eliminar contraseñas o datos personales obvios; también debes considerar qué información podría ser sensible en el contexto específico de tu industria. Un detalle técnico aparentemente inocuo podría revelar aspectos confidenciales de tu infraestructura.</p> <p>El monitoreo continuo es donde muchas empresas fallan. No basta con revisar algunas respuestas al azar de vez en cuando. Necesitas establecer un sistema de logging completo que registre no solo las respuestas del sistema, sino también el contexto completo: qué documentos se utilizaron para generar la respuesta, qué partes del prompt fueron más relevantes, y qué tan seguro estaba el modelo de su respuesta. Esta información es oro cuando necesitas ajustar el sistema o investigar un problema.</p> <p>Los casos límite son donde realmente se pone a prueba la robustez de tu implementación. Por ejemplo, ¿qué sucede cuando un usuario intenta deliberadamente confundir al sistema con preguntas ambiguas o contradictorias? ¿O cuando alguien intenta extraer información haciendo preguntas aparentemente inocentes pero relacionadas que, en conjunto, podrían revelar datos sensibles? Estos escenarios no son paranoia, son situaciones reales que ocurren cuando los sistemas se exponen al mundo real.</p> <p>La clave está en construir capas de protección. Tu primera línea de defensa es el proveedor de IA y sus políticas de seguridad como la RSP de Anthropic. La segunda capa son tus propios filtros y restricciones en el procesamiento RAG. Pero necesitas una tercera capa: políticas claras de respuesta ante incidentes. Si detectas que el sistema ha proporcionado información incorrecta o potencialmente sensible, ¿cuál es el protocolo a seguir? ¿Quién necesita ser notificado? ¿Cómo se documenta y corrige el problema?</p> <p>Y aquí viene algo que pocos mencionan: la importancia de la transparencia con los usuarios. No necesitas explicarles los detalles técnicos de tu implementación, pero sí deberían saber que están interactuando con un sistema de IA, cuáles son sus limitaciones, y en qué casos pueden esperar que sus consultas sean escaladas a un humano.</p> <p>El mantenimiento de un sistema de IA no es como actualizar el software de la oficina, sino que requiere un enfoque más matizado. Cuando tu proveedor de IA lanza una nueva versión de su modelo, no deberías simplemente actualizar y esperar que todo funcione igual. Cada actualización puede traer cambios sutiles en cómo el modelo interpreta y responde a las consultas, incluso si las mejoras parecen obvias en el papel.</p> <p>Por eso es fundamental mantener un ambiente de pruebas robusto. Antes de cualquier actualización, deberías ejecutar tu conjunto completo de casos de prueba, especialmente aquellos casos límite que has ido documentando. Es como hacer un ensayo general antes de un concierto: necesitas asegurarte de que todas las partes siguen funcionando en armonía.</p> <p>La actualización de tu base de conocimientos RAG también requiere un proceso cuidadoso. Cuando agregas nueva documentación o actualizas la existente, necesitas verificar no solo que la nueva información se integre correctamente, sino también que no haya creado inconsistencias con el conocimiento existente. Un documento nuevo podría contradecir información anterior, y tu sistema necesita manejar estas situaciones de manera elegante.</p> <p>Y aquí viene la parte más desafiante: mantener el equilibrio entre seguridad y utilidad. Con el tiempo, podrías sentir la tentación de aflojar algunas restricciones porque el sistema parece estar funcionando bien. Resistir esta tentación es crucial, la seguridad no es algo que puedas relajar solo porque todo ha ido bien hasta ahora.</p> <p>Al final, las políticas de escalamiento responsable como la RSP de Anthropic no son solo documentos abstractos para las grandes empresas de IA. Son un recordatorio de que la implementación de IA es un ejercicio de responsabilidad compartida. Los proveedores hacen su parte asegurando que los modelos base sean seguros y confiables, pero cada empresa que implementa estos sistemas tiene su propio papel que jugar en la cadena de responsabilidad.</p> <p>Cuando vemos titulares alarmistas sobre los riesgos de la IA, es fácil perderse en escenarios apocalípticos y olvidar los riesgos reales y manejables del día a día. La verdadera preocupación no debería ser si la IA va a desarrollar conciencia propia, sino cómo asegurarnos de que nuestras implementaciones específicas sean seguras, precisas y beneficiosas para nuestros usuarios.</p> <p>El escalamiento responsable en tu propia implementación significa crecer de manera sostenible y controlada. No se trata de cuántos usuarios puede manejar tu sistema, sino de cuán bien puede manejarlos. Cada expansión, cada nueva característica, cada actualización debe ser considerada no solo desde la perspectiva de la funcionalidad, sino también desde la ética y la seguridad.</p> <p>En última instancia, la implementación responsable de IA no es un destino, es un viaje continuo. Las políticas y protecciones que implementes hoy necesitarán evolucionar junto con la tecnología y los desafíos que presente. La clave está en mantener siempre presente que la responsabilidad no es algo que puedas delegar completamente en tu proveedor de IA, es parte integral de tu propio proceso de implementación.</p> </div> </article> <article class="md-post md-post--excerpt"> <header class=md-post__header> <div class="md-post__meta md-meta"> <ul class=md-meta__list> <li class=md-meta__item> <time datetime="2025-01-09 00:00:00+00:00">2025/01/09</time></li> <li class=md-meta__item> 5 min read </li> </ul> </div> </header> <div class="md-post__content md-typeset"> <h2 id=evaluaciones-en-ia-lo-que-todos-dicen-hacer-y-pocos-hacen-bien><a href=../../2025/01/09/evaluaciones-en-ia-lo-que-todos-dicen-hacer-y-pocos-hacen-bien/ class=toclink>Evaluaciones en IA: Lo que todos dicen hacer y pocos hacen bien</a></h2> <p><strong>Marcelo Acosta Cavalero</strong> </p> <hr> <p>Si preguntamos en LinkedIn o Twitter* sobre evaluaciones (evals) en proyectos de IA, encontraremos cientos de posts hablando del tema. Todo el mundo parece ser experto en evals. Sin embargo, la realidad es bastante diferente: son pocas las empresas que realmente implementan evaluaciones sistemáticas en sus proyectos de IA, y menos aún las que lo hacen correctamente.</p> <p>Pero antes de seguir, vamos a lo básico: ¿qué son realmente las evals? </p> <p>Imaginen que tienen un empleado nuevo. No basta con contratarlo y asumir que todo va bien, necesitan evaluar su desempeño. Las evals son exactamente eso, pero para sistemas de IA. Son métodos sistemáticos para medir qué tan bien está funcionando tu modelo de IA en las tareas específicas para las que lo implementaste. Y no, no hablo de esa sensación de 'funciona bien' que todos tenemos cuando probamos un chatbot un par de veces.</p> <p>Cuando hablamos de implementar evals, estamos hablando de números concretos, no de sensaciones. Por ejemplo, si implementaste un sistema de IA para clasificar correos de soporte, no basta con que 'parezca que funciona bien'. Necesitas saber exactamente qué porcentaje de correos está clasificando correctamente, cuántos está enviando al departamento equivocado, y cuánto tiempo está tardando en tomar estas decisiones. Y aquí viene lo interesante: muchas empresas descubren que su IA, que parecía funcionar perfectamente en las demos, tiene un rendimiento muy diferente cuando se enfrenta a datos reales del día a día.</p> <p>El problema es que implementar evals no es tan simple como aplicar un test de múltiple opción. Requiere definir métricas específicas para tu caso de uso, crear conjuntos de datos de prueba representativos, y establecer umbrales de rendimiento aceptables. Y aquí es donde muchas empresas cometen su primer error: intentan medir todo, o peor aún, miden las cosas equivocadas.</p> <p>Pensemos en un caso concreto: una empresa decide implementar un asistente de IA para su servicio al cliente. Los directivos están entusiasmados porque en las pruebas iniciales el sistema responde rápido y parece coherente. Pero sin evals adecuadas, no tienen forma de saber si está dando información correcta, si mantiene el tono de marca, o si está escalando correctamente los casos críticos a agentes humanos.</p> <p>Un sistema robusto de evaluación debería medir aspectos como la precisión factual (¿las respuestas son correctas?), la adherencia a políticas (¿respeta los protocolos de seguridad?), y el impacto en métricas de negocio (¿realmente reduce el tiempo de resolución?). </p> <p>Y aquí viene la parte que nadie quiere oír: esto requiere inversión de tiempo y recursos. No existe un atajo mágico ni una herramienta universal que haga todo el trabajo.</p> <p>La estructura de un sistema de evaluación efectivo tiene tres niveles fundamentales. En la base tenemos las evaluaciones automatizadas: scripts que verifican aspectos básicos como tiempos de respuesta, formato de salidas y coherencia en las respuestas. Es la parte más fácil de implementar, pero también la más limitada.</p> <p>La siguiente capa es más compleja: evaluaciones basadas en conjuntos de datos de prueba cuidadosamente seleccionados. Aquí es donde muchas empresas la pifian. No sirve de nada probar tu modelo con casos ideales o inventados, necesitas datos que reflejen la realidad caótica del mundo real, incluyendo esos casos extremos que te dan dolor de cabeza. Si tu IA va a procesar correos en español, necesita manejar desde el español más formal hasta el chileno con modismos y todo.</p> <p>Y en la capa superior están las evaluaciones humanas expertas. Sí, aunque suene antiguo, necesitas personas que entiendan tu negocio revisando periódicamente las respuestas del sistema. No para cada interacción, obviamente, pero sí para mantener un control de calidad consistente.</p> <p>Hablemos de números, porque al final del día eso es lo que más le interesa a cualquier directivo. Implementar un sistema de evaluación puede parecer costoso al principio; estamos hablando de dedicar tiempo de desarrollo, infraestructura y recursos humanos. </p> <p>Pero ¿sabes qué es más costoso? Descubrir que tu IA está cometiendo errores sistemáticos después de meses en producción.</p> <p>Imaginemos un sistema de IA que gestiona devoluciones en un e-commerce. Sin evaluaciones adecuadas, podrías estar aprobando devoluciones innecesarias o, peor aún, rechazando casos legítimos. Cada error tiene un costo directo en dinero y en satisfacción del cliente. Un buen sistema de evaluación puede detectar estos problemas antes de que impacten tu balance.</p> <p>La buena noticia es que no necesitas implementar todo de golpe. Puedes empezar con lo básico: definir métricas clave específicas para tu caso de uso, implementar evaluaciones automatizadas simples, y establecer un proceso de revisión humana periódica. A medida que el sistema madure, también lo harán tus evaluaciones.</p> <p>Entonces, ¿por dónde empezar? El primer paso es más simple de lo que parece: documenta exactamente qué esperas que haga tu sistema de IA. No me refiero a generalidades como 'mejorar la atención al cliente', sino a objetivos concretos y medibles. </p> <p>Por ejemplo: 'responder consultas de primer nivel en menos de 30 segundos con una precisión del 95%'.</p> <p>Una vez definidos los objetivos, necesitas crear tu conjunto inicial de pruebas. Aquí va un consejo que vale oro: empieza con los casos que te han dado problemas en el pasado. Si tienes un histórico de tickets de soporte, busca aquellos que fueron escalados o que generaron quejas. Esos son exactamente el tipo de casos que tu sistema de evaluación debe detectar.</p> <p>Lo siguiente es automatizar lo automatizable. No necesitas un sistema ultra sofisticado desde el día uno. Puedes comenzar con scripts simples que verifiquen cosas básicas: ¿el sistema responde dentro del tiempo límite? ¿Las respuestas tienen el formato correcto? ¿Se están registrando todas las interacciones?</p> <p>La implementación técnica no tiene por qué ser un dolor de cabeza. Muchas empresas se paralizan buscando la solución perfecta, cuando lo importante es empezar con algo funcional y mejorar sobre la marcha. Un sistema básico de monitoreo continuo podría consistir en:</p> <p>Un dashboard simple que muestre las métricas clave en tiempo real. No necesitas 200 gráficos - con 4 o 5 indicadores bien elegidos es suficiente para empezar. Por ejemplo, tasa de respuestas correctas, tiempo promedio de respuesta, tasa de escalamiento a humanos. Un sistema de alertas que avise cuando algo se sale de los parámetros normales. Si tu modelo normalmente tiene una precisión del 95% y de repente cae al 80%, necesitas saberlo inmediatamente, no cuando un cliente se queje. Un proceso de retroalimentación continua. Cada vez que el sistema comete un error, ese caso debe alimentar tu conjunto de pruebas. Es como entrenar un músculo, cada fallo es una oportunidad para fortalecer tus evaluaciones.</p> <p>Lo crucial aquí es mantener registros detallados. Cuando algo falla, necesitas poder responder tres preguntas: ¿qué falló exactamente?, ¿por qué falló?, y ¿cómo evitamos que vuelva a fallar?</p> <p>Para cerrar, volvamos a la realidad del mercado actual: mientras todos hablan de implementar IA, pocos están realmente midiendo su efectividad de manera sistemática. Esta es tu oportunidad de destacar. No es solo sobre tener la tecnología más avanzada, sino sobre saber exactamente qué tan bien funciona y poder demostrarlo con datos concretos.</p> <p>Si estás pensando en implementar IA en tu empresa, o ya lo estás haciendo, las evaluaciones no pueden ser un 'extra opcional' o algo que harás 'cuando tengas tiempo'. Son tan fundamentales como tener un plan de negocio o un control de calidad. Sin ellas, estás básicamente piloteando un avión con los ojos vendados.</p> <p>Y un último consejo práctico: empieza pequeño, pero empieza ya. Es mejor tener un sistema simple de evaluación funcionando hoy, que estar planeando el sistema perfecto que nunca se implementa. La IA es una maratón, no un sprint, y las evaluaciones son tu mapa de ruta para llegar a la meta.</p> </div> </article> <article class="md-post md-post--excerpt"> <header class=md-post__header> <div class="md-post__meta md-meta"> <ul class=md-meta__list> <li class=md-meta__item> <time datetime="2025-01-08 00:00:00+00:00">2025/01/08</time></li> <li class=md-meta__item> 2 min read </li> </ul> </div> </header> <div class="md-post__content md-typeset"> <h2 id=y-ya-implementaste-ia-en-tu-empresa><a href=../../2025/01/08/y-ya-implementaste-ia-en-tu-empresa/ class=toclink>¿Y ya implementaste IA en tu empresa?</a></h2> <p><strong>Marcelo Acosta Cavalero</strong> </p> <hr> <p>Esta pregunta genera más ansiedad en reuniones corporativas que un corte de luz en medio de una presentación importante. Y no es para menos. Parece que todas las empresas están surfeando la ola de la IA mientras la tuya apenas está comprando el bloqueador solar.</p> <p>Si frecuentas LinkedIn, seguramente ya te has topado con la historia del estudiante que resolvió problemas 'imposibles' por accidente. Hay algo en esta historia trillada que tiene más relevancia para la IA de lo que parece.</p> <p>Corría el año 1939 cuando un estudiante universitario llegó tarde a clase (sí, llegar tarde también era cosa en 1939). En la pizarra había dos problemas matemáticos. Sin más contexto, los copió pensando que eran tarea para casa.</p> <p>Plot twist: esos problemas llevaban años sin solución*. Pero como nadie le dijo que eran "imposibles", este estudiante, George Dantzig, los resolvió en unas semanas.</p> <p>Las empresas que hoy sienten que van "tarde" en IA están en una posición similar. Sin el peso de las "mejores prácticas" ni la presión de ser pioneros, pueden ver el panorama con ojos frescos.</p> <p>Mientras algunos early adopters luchan con chatbots que nadie usa y modelos predictivos que predicen el pasado, otras empresas están descubriendo algo interesante: a veces, no ser el primero te da ventajas inesperadas.</p> <p>Una empresa de logística puede elegir entre presumir de chatbots y sistemas predictivos, o puede concentrarse en solucionar un problema concreto: optimizar rutas de entrega. Nada espectacular ni disruptivo, pero algo que ahorra más dinero que todos los chatbots existenciales de su competencia juntos.</p> <p>Aquí viene la parte que nadie quiere escuchar: cuando un proyecto de IA falla, rara vez es por haber llegado tarde o por falta de algoritmos complejos. Parafraseando a <a href=https://www.linkedin.com/in/jxnlco/ >Jason Liu</a>: mientras los consultores te hablan de RAG, fine-tuning y el último modelo de moda, los verdaderos problemas son otros: pérdida de ingresos, objetivos no cumplidos, clientes que se van con la competencia. Todo ese conocimiento técnico vale poco si no entiendes qué está realmente en juego.</p> <p>Mientras el mundo tech corre tras cada nueva tendencia en IA, los 'rezagados' tienen una oportunidad única: pueden aprender de los errores ajenos y enfocarse en crear soluciones que generen impacto real. A veces, la mejor innovación viene de ignorar el ruido y concentrarse en lo que verdaderamente importa.</p> <ul> <li>Nota técnica: Para los amantes de la precisión histórica; los problemas que Dantzig resolvió no eran exactamente "problemas sin solución", sino teoremas estadísticos no probados para los cuales él desarrolló las demostraciones matemáticas. </li> </ul> </div> </article> <nav class=md-pagination> </nav> </div> </div> <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../../category/web-development/ class="md-footer__link md-footer__link--prev" aria-label="Previous: Web Development"> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </div> <div class=md-footer__title> <span class=md-footer__direction> Previous </span> <div class=md-ellipsis> Web Development </div> </div> </a> <a href=../2024/ class="md-footer__link md-footer__link--next" aria-label="Next: 2024"> <div class=md-footer__title> <span class=md-footer__direction> Next </span> <div class=md-ellipsis> 2024 </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2025 Marcelo Acosta Cavalero </div> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <div class=md-social> <a href=https://www.linkedin.com/in/marceloacostacavalero/ target=_blank rel=noopener title=www.linkedin.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5m282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z"/></svg> </a> <a href=https://github.com/marceloacosta target=_blank rel=noopener title=github.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "../../..", "features": ["announce.dismiss", "content.action.edit", "content.action.view", "content.code.annotate", "content.code.copy", "content.code.select", "content.tabs.link", "content.tooltips", "header.autohide", "navigation.expand", "navigation.footer", "navigation.indexes", "navigation.prune", "navigation.sections", "navigation.tabs", "navigation.tabs.sticky", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest", "toc.follow"], "search": "../../../assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script> <script src=../../../assets/javascripts/bundle.13a4f30d.min.js></script> <script src=../../../javascripts/mathjax.js></script> <script src=../../../javascripts/analytics.js></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> </body> </html>